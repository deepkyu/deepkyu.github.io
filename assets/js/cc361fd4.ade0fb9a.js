"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[7939],{4985:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>g,contentTitle:()=>o,default:()=>f,frontMatter:()=>s,metadata:()=>r,toc:()=>c});var a=n(5893),i=n(1151);n(8952),n(4716),n(8076),n(1488),n(3440),n(3723),n(2026),n(1451),n(8087),n(7558),n(63);const s={slug:"diffaugment",title:"Differentiable Augmentation for Data-Efficient GAN Training",description:"\uc801\uc740 \ub370\uc774\ud130\ub85c \ud6a8\uc728\uc801\uc73c\ub85c GAN \ud559\uc2b5\ud558\ub294 \ubc29\ubc95\uc744 \ud655\uc778\ud574\ubd05\ub2c8\ub2e4.",image:"img/default.png",authors:["hkyu"],tags:["paper-review","gan"]},o=void 0,r={permalink:"/papers/diffaugment",source:"@site/papers/2021-05-03-paper-review-diffaugment/index.mdx",title:"Differentiable Augmentation for Data-Efficient GAN Training",description:"\uc801\uc740 \ub370\uc774\ud130\ub85c \ud6a8\uc728\uc801\uc73c\ub85c GAN \ud559\uc2b5\ud558\ub294 \ubc29\ubc95\uc744 \ud655\uc778\ud574\ubd05\ub2c8\ub2e4.",date:"2021-05-03T00:00:00.000Z",formattedDate:"May 3, 2021",tags:[{label:"paper-review",permalink:"/papers/tags/paper-review"},{label:"gan",permalink:"/papers/tags/gan"}],readingTime:6.865,hasTruncateMarker:!0,authors:[{name:"Hyoung-Kyu Song",title:"AI Researcher (Vision)",url:"https://github.com/deepkyu",imageURL:"https://github.com/deepkyu.png",key:"hkyu"}],frontMatter:{slug:"diffaugment",title:"Differentiable Augmentation for Data-Efficient GAN Training",description:"\uc801\uc740 \ub370\uc774\ud130\ub85c \ud6a8\uc728\uc801\uc73c\ub85c GAN \ud559\uc2b5\ud558\ub294 \ubc29\ubc95\uc744 \ud655\uc778\ud574\ubd05\ub2c8\ub2e4.",image:"img/default.png",authors:["hkyu"],tags:["paper-review","gan"]},unlisted:!1,prevItem:{title:"Anycost GANs for Interactive Image Synthesis and Editing",permalink:"/papers/anycost"},nextItem:{title:"FreezeD: a Simple Baseline for Fine-tuning GANs",permalink:"/papers/freezed"}},g={authorsImageUrls:[void 0]},c=[];function p(e){const t={a:"a",blockquote:"blockquote",br:"br",img:"img",p:"p",...(0,i.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.p,{children:(0,a.jsx)(t.a,{href:"https://github.com/mit-han-lab/data-efficient-gans",children:(0,a.jsx)(t.img,{src:"https://img.shields.io/static/v1?message=Official%20Repo&logo=Github&labelColor=grey&color=blue&logoColor=white&label=%20&style=flat-square",alt:"githubio"})})}),"\n",(0,a.jsxs)(t.blockquote,{children:["\n",(0,a.jsxs)(t.p,{children:['Zhao, Shengyu, et al. "Differentiable augmentation for data-efficient gan training."',(0,a.jsx)(t.br,{}),"\n","Advances in Neural Information Processing Systems 33 (2020): 7559-7570."]}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"\ucc38\uace0\ub85c Song Han \uc5f0\uad6c\uc2e4\uc740 Neural Network Compression \ubd84\uc57c\uc5d0 \uc788\uc5b4 Top\uc744 \ub2ec\ub9ac\uace0 \uc788\ub294 \uc5f0\uad6c\uc2e4\uc774\ub2e4. \ud6c4\uc5d0 \uc18c\uac1c\ud560 AnycostGAN\uc5d0\uc11c\ub3c4 DiffAugment\uac00 \uc5b8\uae09\uc774 \ub41c\ub2e4."}),"\n",(0,a.jsx)(t.p,{children:"Han Lab\uc740 \uae30\uc874\uc5d0\ub294 \ubc29\ubc95\ub860\uc5d0 \uc788\uc5b4 Network Pruning, KD(Knowledge Distillation) \ub4f1\uc5d0 \uc9d1\uc911\uc744 \ud588\uace0, TinyTL \ub4f1 Activation\uc5d0 \ub300\ud55c \uacbd\ub7c9\ud654\ub3c4 \uc5f0\uad6c\ub97c \uc9c4\ud589\ud588\ub2e4. \ub2e4\ub9cc, \ub300\ubd80\ubd84 Task\uac00 Image Recognition\uc5d0 \uad6d\ud55c\ub418\uc5b4 \uc788\uc5c8\ub2e4. Song Han\uc740 CVPR2020\uc5d0\uc11c GAN Compression\uc774\ub77c\ub294 \ub17c\ubb38\uc744 \ud1b5\ud574 Image Generation\uc5d0 \ub300\ud55c Compression \ub17c\ubb38\uc744 \uc2dc\uc791\uc73c\ub85c, GAN \uad00\ub828 \uc5f0\uad6c\ub97c \uc9c0\uc18d\ud574\uc11c \uc774\uc5b4\uc624\uace0 \uc788\ub2e4."})]})}function f(e={}){const{wrapper:t}={...(0,i.a)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}},8952:(e,t,n)=>{n.d(t,{Z:()=>a});const a={small:"small_f2c9",medium:"medium_sJ4m",figCenter:"figCenter__7gH"}},4716:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/ablation_augmentation-6fad8d2422af1ae0b528dfa994cf5049.png"},1488:(e,t,n)=>{n.p},8076:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/augmentation_type_result-e03bdd14ef6248c21157d69ba3f953af.png"},3440:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/d_overfitting-0fde96f1fa39bd9365ce7230b620fffb.png"},3723:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/interpolation-a37d53f43c37be1bde34d1839ecf1837.png"},2026:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/model_size_fid-b395637cdd2677201a79958933acd29f.png"},1451:(e,t,n)=>{n.p},8087:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/result_compare-acc36d84cc9ea455714866e23cef7a61.png"},7558:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/training_method-182e7e89d5035fa3118b77161271b12b.png"},63:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/vs_stylegan2-f1b3f845a404ca098b35e023e87f8a99.png"},1151:(e,t,n)=>{n.d(t,{Z:()=>r,a:()=>o});var a=n(7294);const i={},s=a.createContext(i);function o(e){const t=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),a.createElement(s.Provider,{value:t},e.children)}}}]);