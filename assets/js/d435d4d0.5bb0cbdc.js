"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[4723],{9945:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"acon","metadata":{"permalink":"/papers/acon","source":"@site/papers/2021-07-19-paper-review-acon/index.mdx","title":"Activate or Not: Learning Customized Activation","description":"Swish\uc640 ReLU\uc640\uc758 \uad00\uacc4\ub97c \uc124\uba85\ud558\uace0, \ud559\uc2b5\uc774 \uac00\ub2a5\ud55c \ud65c\uc131\ud568\uc218\ub97c \uc18c\uac1c\ud569\ub2c8\ub2e4.","date":"2021-07-19T00:00:00.000Z","formattedDate":"July 19, 2021","tags":[{"label":"paper-review","permalink":"/papers/tags/paper-review"},{"label":"activation","permalink":"/papers/tags/activation"}],"readingTime":14.65,"truncated":false,"authors":[{"name":"Hyoung-Kyu Song","title":"AI Researcher (Vision)","url":"https://github.com/deepkyu","imageURL":"https://github.com/deepkyu.png","key":"hkyu"}],"frontMatter":{"slug":"acon","title":"Activate or Not: Learning Customized Activation","description":"Swish\uc640 ReLU\uc640\uc758 \uad00\uacc4\ub97c \uc124\uba85\ud558\uace0, \ud559\uc2b5\uc774 \uac00\ub2a5\ud55c \ud65c\uc131\ud568\uc218\ub97c \uc18c\uac1c\ud569\ub2c8\ub2e4.","image":"img/default.png","authors":["hkyu"],"tags":["paper-review","activation"]},"nextItem":{"title":"Differentiable Augmentation for Data-Efficient GAN Training","permalink":"/papers/diffaugment"}},"content":"import clsx from \'clsx\';\\nimport styles from \'../blog.module.css\';\\n\\nimport figSwish from \'./image/figure1_swish.png\';\\nimport figAcon from \'./image/figure4_acon.png\';\\nimport figFamily from \'./image/figure5_maxout_family_acon_family.png\';\\nimport figExample from \'./image/figure6_acon_example.png\';\\nimport figProperty from \'./image/figure7_acon_property.png\';\\nimport figDistribution from \'./image/figure8_meta_acon_distribution.png\';\\nimport figResultFour from \'./image/figure12_result4.png\';\\nimport figResultFive from \'./image/figure13_result5.png\';\\n\\n[![arXiv](https://img.shields.io/badge/arXiv-2009.04759-brightgreen.svg?style=flat-square)](https://arxiv.org/abs/2009.04759)\\n[![githubio](https://img.shields.io/static/v1?message=Official%20Repo&logo=Github&labelColor=grey&color=blue&logoColor=white&label=%20&style=flat-square)](https://github.com/nmaac/acon)\\n\\n> Ma, Ningning, et al. \\"Activate or Not: Learning Customized Activation.\\"  \\n> Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\\n\\n<br/>\\n\\n:::info\\n\\n\uc5c5\ubb34 \uc911\uc5d0 \uc9c4\ud589\ub41c \ub17c\ubb38 \ub9ac\ubdf0\ub85c [\ub9c8\uc778\uc988\ub7a9 Brain\ud300 Tech Blog](https://mindslab-ai.github.io)\uc5d0\uc11c\ub3c4 \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n:::\\n\\n## \uba3c\uc800 \uc54c\uba74 \uc88b\uc740 \uac83\ub4e4\\n\\n### Swish Activation Function [<sup>[1]</sup>](#r1)\\n\\n$$\\n\\\\operatorname{swish}(x):=x \\\\times \\\\sigma(\\\\beta x)=\\\\frac{x}{1+e^{-\\\\beta x}}\\n$$\\n\\n<img className={styles.figCenter} src={figSwish} alt=\\"figure1_swish\\" />\\n\\n- Linear Function\uacfc ReLU \uc0ac\uc774\uc5d0\uc11c\uc758 non-linearly interpolated activation\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\\n    - $\u03b2 = 0$ \uc77c \uacbd\uc6b0, Linear function $f(x) = x/2$ \ucc98\ub7fc \uc791\uc6a9\ud558\uac8c \ub429\ub2c8\ub2e4.\\n    - \ubc18\ub300\ub85c $\u03b2 \u2192 \u221e$\uc77c \uacbd\uc6b0, Sigmoid\uc5d0 \ud574\ub2f9\ud558\ub294 \ubd80\ubd84\uc774 0-1 activation\ucc98\ub7fc \uc791\uc6a9\ud558\uac8c \ub418\uc5b4, Swish\uac00 ReLU\ucc98\ub7fc \uc791\uc6a9\ud558\uac8c \ub429\ub2c8\ub2e4.\\n    - $\u03b2 = 1$\uc77c \uacbd\uc6b0, \uac15\ud654\ud559\uc2b5\uc5d0\uc11c \uc0ac\uc6a9\ub418\ub294 Sigmoid-weighted Linear Unit (SiL) function\ucc98\ub7fc \uc791\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n    - $\u03b2$\ub294 \uc704\uc5d0\uc11c \ubcf4\uc2e0 \uac83\ucc98\ub7fc \uc5b4\ub5a4 \uc0c1\uc218\uc77c \uc218\ub3c4 \uc788\uace0, \ubaa8\ub378\uc5d0 \ub530\ub77c\uc11c\ub294 \ud6c8\ub828 \uac00\ub2a5\ud55c \ud30c\ub77c\ubbf8\ud130\uac00 \ub420 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\\n- \ube0c\ub808\uc778\ud300 AI Scientist\ubd84\ub4e4\uc774 \uc790\uc8fc \uc0ac\uc6a9\ud558\uc2dc\ub294 Activation Function\uc774\uae30\ub3c4 \ud558\uc8e0 \ud83d\ude42\\n- Generative Model\uc5d0\uc11c\ub3c4 ReLU \ub300\uc2e0 \uc0ac\uc6a9\ud558\ub294 \uacbd\uc6b0\uac00 \ub9ce\uc774 \uc788\uc2b5\ub2c8\ub2e4.\\n- \ucd5c\uadfc\uc5d0\ub294 Implicit Representation Network \uc0c1\uc5d0\uc11c\ub3c4 Swish\uac00 \ub2e4\uc2dc\uae08 \uc8fc\ubaa9\uc744 \ubc1b\uace0 \uc788\uc2b5\ub2c8\ub2e4.\\n    - SIREN\uc5d0\uc11c \uc5b8\uae09\ud558\ub294 periodic function activation (Sine \ud568\uc218 \ub4f1) \ubcf4\ub2e4 Swish\uac00 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294 Task\uac00 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n### Sigmoid\\n\\n$$\\n\\\\sigma(x)=\\\\frac{1}{1+e^{-x}}\\n$$\\n\\n- \uc5ec\uae30\uc11c\ub294 Activation\uc73c\ub85c \uc2dc\uc0ac\ud558\uae30\ubcf4\ub2e4\ub294 \uc218\uc2dd \ud45c\ud604 \uc2dc\uc5d0 sigmoid\ub85c \ubb36\uc5b4 \ud45c\ud604\ud558\uae30 \uc704\ud574 \ud655\uc778\ud558\uace0 \ub118\uc5b4\uac00\uc57c \ud569\ub2c8\ub2e4.\\n- Swish\uac00 \uacb0\uad6d **input \uac12\uc5d0 sigmoid\ud55c \uac83\uacfc input \uac12\uc758 \uacf1\uc73c\ub85c \ud45c\ud604\ub41c\ub2e4**(\u03b2 \ub97c \uacf1\ud558\uae30\ub294 \ud558\uaca0\uc9c0\ub9cc)\ub294 \uac83\ub3c4 \ub2e4\uc2dc \ud55c\ubc88 \ub9ac\ub9c8\uc778\ub4dc\ud558\uace0 \ub118\uc5b4\uac11\uc2dc\ub2e4 \ud83d\ude0e\\n\\n### Maxout Family\\n\\n- ReLU\uc640 \uac19\uc740 Activation Function\uc758 \ucd9c\ubc1c\uc810\uc5d0 \ud574\ub2f9\ud558\ub294 \uac1c\ub150 \uc911 \ud558\ub098\uc785\ub2c8\ub2e4.\\n- Goodfellow\uc640 Bengio\uc758 \ub17c\ubb38[<sup>[2]</sup>](#r2) \uc73c\ub85c, Maximum\uc744 \uc120\ud0dd\ud558\ub294 \uac83\uc73c\ub85c\ub3c4 \uc784\uc758\uc758 Convex Function\uc5d0 \ub300\ud574 \ub450\ub8e8 \uadfc\uc0ac\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.\\n\\n## Main Idea\\n\\n### ACON(**Ac**tivationOrNot) Activation Function\\n\\n$$\\n\\\\operatorname{ACON-C}(x) := \\\\left(p_{1}-p_{2}\\\\right) x \\\\cdot \\\\sigma\\\\left(\\\\beta\\\\left(p_{1}-p_{2}\\\\right) x\\\\right)+p_{2} x\\n$$\\n\\n<img className={styles.figCenter} src={figAcon} alt=\\"figure4_acon\\" />\\n\\n*ACON Activation\uc744 \uc0ac\uc6a9\ud558\uc600\uc744 \ub54c, \ud2b9\uc815 Layer\uc758 Activation\uc774 Linear \ud558\uac8c pass\uc218\ub3c4, Non-linear Activation\uc73c\ub85c \ud65c\uc131\ub420 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4*\\n\\n\uc800\uc790\ub294 ACON(\ub354 \ub098\uc544\uac00\uc11c Meta-ACON)\uc774\ub77c\uace0 \ud558\ub294 Activation Function\uc744 \uc81c\uc548\ud569\ub2c8\ub2e4. ACON activation\uc740 trainable\ud55c activation\uc73c\ub85c Neuron\uc744 Activation\ud560 \uc9c0 \uc548 \ud560\uc9c0\ub97c \uac01 Layer\uc758 \ud2b9\uc131\uc5d0 \ub9de\uac8c \uacb0\uc815\ud569\ub2c8\ub2e4.\\n\\n\\n\\n### \uc5b4\ub5bb\uac8c \ud574\uc11c ACON \uc2dd\uc744 \ub3c4\ucd9c\ud560 \uc218 \uc788\uac8c \ub418\uc5c8\uc744\uae4c\uc694?\\n\\n\uba3c\uc800 Maximum Function $max(x1, ..., xn)$ \uc5d0 \ub300\ud574 smooth\ub41c \ubc84\uc804\uc744 \ubcf4\uc544\uc57c \ud569\ub2c8\ub2e4. Maximum\uc744 \uad6c\ud55c\ub2e4\ub294 \uac83\uc740 \uc77c\ubc18\uc801\uc73c\ub85c differentiable\ud558\uc9c0 \uc54a\uc9c0\ub9cc, \uc774\ub97c smooth\ud55c \ud568\uc218\ub294 differentiable\ud558\uac8c \ub429\ub2c8\ub2e4.\\n\\n\ubcf4\ud1b5 \uc544\ub798\uc758 \uc2dd\ucc98\ub7fc \ud45c\ud604\ud569\ub2c8\ub2e4.\\n\\n$$\\nS_{\\\\beta}\\\\left(x_{1}, \\\\ldots, x_{n}\\\\right)=\\\\frac{\\\\sum_{i=1}^{n} x_{i} e^{\\\\beta x_{i}}}{\\\\sum_{i=1}^{n} e^{\\\\beta x_{i}}}\\n$$\\n\\n\uc774 \ub54c, $\u03b2$ \ub294 switching factor\ub85c\uc11c\\n\\n- $\u03b2 \u2192 \u221e$\uc77c \ub54c, \uc8fc\uc5b4\uc9c4 \ud568\uc218\ub294 Maximum Function \uc758 \uc5ed\ud560\uc744 \ud558\uac8c \ub429\ub2c8\ub2e4.\\n- $\u03b2 \u2192 0$\uc77c \ub54c, \uc8fc\uc5b4\uc9c4 \ud568\uc218\ub294 \uc0b0\uc220\ud3c9\uade0(Arithmetic Mean, \uc6b0\ub9ac\uac00 \uc77c\ubc18\uc801\uc73c\ub85c \uc544\ub294 \ud3c9\uade0)\ucc98\ub7fc \uc791\ub3d9\ud569\ub2c8\ub2e4.\\n\\n\uc77c\ubc18\uc801\uc73c\ub85c Neural Network\uc5d0\uc11c \ub9ce\uc774 \uc0ac\uc6a9\ud558\ub294 Activation Function\ub4e4\uc740 \uc704\uc5d0\uc11c \uc5b8\uae09\ud55c Maxout\uc5d0 \uc900\ud558\ub294 \uac83\uc73c\ub85c \ud45c\ud604\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n$$\\nmax( \u03b7a(x), \u03b7b(x))\\n$$\\n\\n\uc608\ub97c \ub4e4\uc5b4, ReLU\ub294 $\u03b7a(x)=x$, $\u03b7b(x)=0$\uc778 \uac83\uc73c\ub85c \uc0dd\uac01\ud558\uba74, \uc774 \uc5ed\uc2dc Maxout Family\uc5d0 \uc18d\ud55c\ub2e4\uace0 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \\nLeaky ReLU, FReLU \ub4f1\ub3c4 \uc774\ub7ec\ud55c \ubc29\uc2dd\uc73c\ub85c \uc811\uadfc\ud574\ubcf4\uba74 \ubaa8\ub450 Maxout Family\uc5d0 \uc18d\ud558\uac8c \ub429\ub2c8\ub2e4.\\n\\n\ubcf8 \ub17c\ubb38\uc5d0\uc11c\uc758 \ubaa9\ud45c\ub294 Maximum Function\uacfc \uc704 Maxout Family\ub97c \ud568\uaed8 \uc0ac\uc6a9\ud558\uc5ec, Maxout Family \uac01\uac01\uc5d0 \uc0c1\uc751\ud558\ub294 activation function\ub4e4\uc744 smooth\ud55c \ud568\uc218\ub85c \uadfc\uc0ac\ud574\ubcf4\ub294 \uac83\uc785\ub2c8\ub2e4. \uc704\uc5d0\uc11c Smooth\ub41c Maximum Function\uc744 \uc791\uc131\ud560 \ub54c, \uc785\ub825 \uac12\uc758 \uac1c\uc218\ub97c 2\uac1c\ub85c\ub9cc \ud55c\uc815\ud574\uc11c \uc2dd\uc744 \uc804\uac1c\ud558\uba74 \ub531\uc774\uaca0\ub124\uc694!\\n\\n$$\\n\\\\begin{array}{l}S_{\\\\beta}\\\\left(\\\\eta_{a}(x), \\\\eta_{b}(x)\\\\right) \\\\\\\\=\\\\eta_{a}(x) \\\\cdot \\\\frac{e^{\\\\beta \\\\eta_{a}(x)}}{e^{\\\\beta \\\\eta_{a}(x)}+e^{\\\\beta \\\\eta_{b}(x)}}+\\\\eta_{b}(x) \\\\cdot \\\\frac{e^{\\\\beta \\\\eta_{b}(x)}}{e^{\\\\beta \\\\eta_{a}(x)}+e^{\\\\beta \\\\eta_{b}(x)}} \\\\\\\\=\\\\eta_{a}(x) \\\\cdot \\\\frac{1}{1+e^{-\\\\beta\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right)}}+\\\\eta_{b}(x) \\\\cdot \\\\frac{1}{1+e^{-\\\\beta\\\\left(\\\\eta_{b}(x)-\\\\eta_{a}(x)\\\\right)}} \\\\\\\\=\\\\eta_{a}(x) \\\\cdot \\\\sigma\\\\left[\\\\beta\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right)\\\\right]+\\\\eta_{b}(x) \\\\cdot \\\\sigma\\\\left[\\\\beta\\\\left(\\\\eta_{b}(x)-\\\\eta_{a}(x)\\\\right)\\\\right] \\\\\\\\=\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right) \\\\cdot \\\\sigma\\\\left[\\\\beta\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right)\\\\right]+\\\\eta_{b}(x)\\\\end{array}\\n$$\\n\\n\uc989, Smooth\ub41c Maximum Function\uc5d0 \ub300\uc785\ud574\uc11c \uc804\uac1c\ud574\ubcf4\uba74\\n\\n$$\\n\\\\begin{array}{l}S_{\\\\beta}\\\\left(\\\\eta_{a}(x), \\\\eta_{b}(x)\\\\right) =\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right) \\\\cdot \\\\sigma\\\\left[\\\\beta\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right)\\\\right]+\\\\eta_{b}(x)\\\\end{array}\\n$$\\n\\n\uc774 \ub420 \uac83\uc785\ub2c8\ub2e4!\\n\\n### ACON \uc548\uc5d0 Swish \uc788\ub2e4 \ud83d\ude09\\n\\n\uc790, \uadf8\ub7fc \uc544\uae4c \uc5b8\uae09\ud55c Maxout Family\uc5d0 \uc900\ud558\uc5ec \uc5ec\ub7ec Activation\uc744 \ud45c\ud604\ud560 \uc218 \uc788\uc5c8\ub2e4\uba74, \uac01\uac01\uc744 Smooth\ub41c Maximum Function\uc5d0 \ud574\ub2f9\ud558\ub3c4\ub85d \uc804\uac1c\ub97c \ud574\ubcfc\uae4c\uc694?\\n\\n<img className={styles.figCenter} src={figFamily} alt=\\"figure5_maxout_family_acon_family\\" />\\n\\n\\nReLU\uc758 smooth\ub418\ub294 \ubc84\uc804\uc774 Swish\ub77c\ub294 \uac74 \uc9c1\uad00\uc73c\ub85c\ub3c4 \ub9ce\uc774\ub4e4 \uc774\ud574\ud558\uace0 \uc788\uc5c8\ub294\ub370\uc694. \uc774 \uc2dd\uc5d0\uc11c \ubcf4\ub4ef\uc774 Smooth\ub41c Maximum Function\uc5d0 \ub300\uc785\ud574\uc11c \uc804\uac1c\ud574\ubcf4\uba74, \ubc14\ub85c Swish \uc2dd\uc774 \ub098\uc624\uac8c \ub429\ub2c8\ub2e4. \uc800\uc790\ub294 \uc774\ub97c \ud1b5\ud574 Swish\uac00 ReLU\uc758 Smooth Approximation\uc784\uc744 \ud45c\ud604\ud560 \uc218 \uc788\uac8c \ub41c\ub2e4\uace0 \ub9d0\ud569\ub2c8\ub2e4.\\n\\n\ub610\ud55c, Leaky ReLU\uc758 \uc0c1\uc704 \ud638\ud658\uc774\uae30\ub3c4 \ud55c PReLU(Parametric ReLU, \uc74c\uc218 \ubd80\ubd84\uc758 \uae30\uc6b8\uae30 \uac12\uc774 learnable\ud568)\ub3c4 \uc0b4\ud3b4\ubcf4\uba74, \uc5ed\uc2dc Smooth\ub418\ub294 \ud568\uc218\ub85c \ub300\uc751\ud558\ub294 \uac83\uc744 \ucc3e\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. (\uc544 \uc774 \ub54c PReLU\uc5d0 \ub300\uc751\ud558\ub824\uba74, p < 1 \uc778 \uac78\ub85c \ud55c\uc815\ud574\uc11c \uc0dd\uac01\ud574\ubd10\uc694 \uc6b0\ub9ac \ud83d\ude42)\\n\\n\uadf8\ub9ac\uace0 \ub9c8\uc9c0\ub9c9\uc73c\ub85c \uac01 \uc120\ud615 \ud568\uc218\uc758 \uac00\uc911\uce58(Cartesian \uc88c\ud45c\uacc4 \uc0c1\uc740 \uae30\uc6b8\uae30\uaca0\uc8e0?)\uac00 p1, p2\ub85c \ud45c\ud604\ud558\uba74 \uac00\uc7a5 \uc77c\ubc18\ud654\ub41c \ud45c\ud604\uc77c\ud150\ub370\uc694 (p1 \u2260 p2). \uc5ec\uae30\uc5d0 \uac01\uac01 Maxout Family, ACON Family\ub97c \ub300\uc751\ud574\ubcf4\uba74 \uc77c\ubc18\ud654\ub41c \uc2dd\uc774 \ub098\uc635\ub2c8\ub2e4. \uc704\uc5d0\uc11c \uc5b8\uae09\ud55c\\n\\n$$\\n\\\\operatorname{ACON-C}(x):=\\\\left(p_{1}-p_{2}\\\\right) x \\\\cdot \\\\sigma\\\\left(\\\\beta\\\\left(p_{1}-p_{2}\\\\right) x\\\\right)+p_{2} x\\n$$\\n\\n\uc774 \uc774\ub807\uac8c \uc720\ub3c4\ub418\uac8c \ub418\ub294 \uac83\uc774\uc8e0!\\n\\n\uc0ac\uc2e4 Maxout Family\uc5d0\uc11c \ube44\uad50\ud558\uac8c \ub418\ub294 \ub450 \ud568\uc218\ub294 \uc704\uc5d0\uc11c\ucc98\ub7fc \ub2e8\uc21c\ud558\uc9c0 \uc54a\uc744 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. \uac01\uac01\uc774 \ubcf5\uc7a1\ud574\uc9c8\uc218\ub85d \ub354 \ub9ce\uc740 \ud568\uc218\ub4e4\uc744 \ud45c\ud604\ud560 \uc218 \uc788\uac8c \ub418\uc8e0. \ub2e4\ub9cc, \uc800\uc790\ub294 \uc774 Maxout Family\ub97c ACON Family\ub85c \ubc14\uafe8\uc744 \ub54c(\uc989, Smooth Maximum Function\uc73c\ub85c \uadfc\uc0ac\ud588\uc744 \ub54c)\uc758 \ud6a8\uacfc\ub97c \ubcf4\ub294 \ub370\uc5d0 \uc5f0\uad6c\ub97c \uc9d1\uc911\ud588\ub2e4\uace0 \ud574\uc694. \ud5a5\ud6c4 \uc5f0\uad6c\uc5d0\uc11c \ub354 \uc804\uccb4\uc801\uc778 Scope\uc5d0\uc11c\uc758 \ube44\uad50\uac00 \uc788\uae30\ub97c \uae30\ub300\ud574\ubd05\ub2c8\ub2e4!\\n\\n### ACON\uc758 \ud2b9\uc131\\n\\nACON\uc5d0 \ud2b9\uc815 \uac12\uc744 \ub300\uc785\ud574\uc11c \ud55c\ubc88 \uc0b4\ud3b4\ubcfc\uae4c\uc694?\\n\\n<img className={styles.figCenter} src={figExample} alt=\\"figure6_acon_example\\" />\\n\\np1=1.2, p2=-0.8\uc77c \ub54c ACON-C\uc5d0 \ub300\uc751\ud558\ub294 \uc2dd\uc744 \uc5ec\ub7ec \u03b2\uac12\uc5d0 \ub300\ud574 \ud45c\ud604\ud55c graph\uc785\ub2c8\ub2e4.\\n\\n- \u03b2\uac00 \ud074 \ub54c\ub294, maximum function\ucc98\ub7fc \ubc18\uc751\ud558\uc5ec \ube44\uc120\ud615\uc801\uc778 \ud2b9\uc131\uc744 \uac16\uac8c \ub418\uace0\uc694.\\n- \u03b2\uac00 0\uc5d0 \uac00\uae4c\uc6b8 \ub54c\ub294 mean function\uc5d0 \uadfc\uc0ac\ub418\uc5b4 \uc120\ud615\uc801\uc778 \ud2b9\uc131\uc744 \uac16\ub124\uc694.\\n\\n<img className={styles.figCenter} src={figProperty} alt=\\"figure7_acon_property\\" />\\n\\nACON Activation\uacfc \uc774\uc5d0 \ub300\ud55c \ub3c4\ud568\uc218(derivative)\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub9bc\uc785\ub2c8\ub2e4.\\n\\n- \uc67c\ucabd: \u03b2\uac00 fixed \ub418\uc5b4 \uc788\uc744 \ub54c, p1, p2 \uacc4\uc218\uc5d0 \ub530\ub77c \uc5b4\ub5bb\uac8c Activation function\uc774 \ub2ec\ub77c\uc9c0\ub294 \uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\\n- \uac00\uc6b4\ub370: \u03b2 \uac12\uc774 \ub2ec\ub77c\uc9d0\uc5d0 \ub530\ub77c ACON\uc758 \ub3c4\ud568\uc218\uac00 \ubcc0\ud654\ud558\uac8c \ub418\uace0 \uc774\ub97c \ud1b5\ud574 \u03b2\uc758 \uc5ed\ud560\uc744 \uc9d0\uc791\ud574\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n- \uc624\ub978\ucabd: \u03b2\uac00 fixed \ub418\uc5b4 \uc788\uc744 \ub54c, p1, p2 \uacc4\uc218\uc5d0 \ub530\ub77c ACON\uc758 \ub3c4\ud568\uc218\uac00 \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294 \uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\\n\\nACON\uc758 \ub3c4\ud568\uc218\ub97c \ubcf4\uba74\uc11c \uc544\ub798\uc640 \uac19\uc740 \uc0ac\uc2e4\uc744 \uc54c \uc218 \uc788\uc5b4\uc694.\\n\\n- p1, p2\ub294 \uac01\uac01 Upper/Lower Bound\uc5d0 \ud574\ub2f9\ud558\ub294 \uac12\uc744 \uacb0\uc815\ud558\uac8c \ub429\ub2c8\ub2e4.\\n- \u03b2 \uac12\uc740 \ub3c4\ud568\uc218 \uc0c1\uc5d0\uc11c p1, p2\uc5d0 \uc758\ud574 \uacb0\uc815\ub41c Upper/Lower Bound\uc5d0 \uc5bc\ub9c8\ub098 \ube60\ub974\uac8c \uadfc\uc0ac\ub418\ub294 \uc9c0\ub97c \uacb0\uc815\ud558\uac8c \ub429\ub2c8\ub2e4.\\n\\nSwish\uc5d0\uc11c\ub294 Hyperparameter \u03b2\ub9cc\uc774 Upper/Lower Bound\uc5d0 \uc5bc\ub9c8\ub098 \ube68\ub9ac \uadfc\uc0ac\ub418\ub294 \uc9c0\ub97c \uacb0\uc815\ud558\uac8c \ub418\ub294\ub370\uc694. ACON\uc5d0\uc11c\ub294 p1, p2\uac00 \uc774 Bound \uac12\uc744 \uacb0\uc815\ud558\uac8c \ub418\uace0, \uc774 \uc5ed\uc2dc learnable\ud574\uc9c8 \uc218 \uc788\ub2e4\ub294 \ud2b9\uc131\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub807\uac8c boundary\uac00 learnable\ud558\ub2e4\ub294 \uac83\uc740 optimization\uc744 \uc27d\uac8c \ud558\ub294 \ub370\uc5d0 \ud544\uc218\uc801\uc778 \ud2b9\uc131\uc774\uace0, \uc800\uc790\ub294 \uc774 \uc7a5\uc810\uc744 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ud1b5\ud574 \ubcf4\uc5ec\uc8fc\uace0 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n### \ud559\uc2b5\uc5d0 \ubaa8\ub450 \ub9e1\uaca8\ubc84\ub9ac\uc790! Meta-ACON\\n\\nMeta-ACON\uc740 \u03b2 \uc790\uccb4\ub97c Learnable\ud55c parameter\ub85c \ub194\ub450\ub294 \uac83\uc5d0\uc11c \ub354 \ub098\uc544\uac00, Layer\uc5d0 \uc785\ub825\ub418\ub294 feature map\uc73c\ub85c\ubd80\ud130 FC Layers\ub97c \uac70\uccd0 estimation \ub418\ub3c4\ub85d \ub9cc\ub4e0 \uac83\uc785\ub2c8\ub2e4.\\n\\n<img className={styles.figCenter} src={figDistribution} alt=\\"figure8_meta_acon_distribution\\" />\\n\\nACON\uacfc meta-ACON\uc744 \ube44\uad50\ud55c \ub3c4\uc2dd\uc785\ub2c8\ub2e4. ResNet50\uc758 \ub9c8\uc9c0\ub9c9 BottleNeck Layer\uc5d0\uc11c\uc758 activation\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \uc5ec\uae30\uc5d0\uc11c 7\uac1c\uc758 sample\uc744 \uc784\uc758\ub85c \ucd94\ucd9c\ud574\ubd24\uc2b5\ub2c8\ub2e4.\\n\\n- ACON\uc5d0\uc11c \ucd94\ucd9c\ud560 \uacbd\uc6b0, \ud30c\ub780 \ud788\uc2a4\ud1a0\uadf8\ub7a8\uc5d0 \ud574\ub2f9\ud558\ub294\ub370\uc694. 7\uac1c\uc758 sample\uc774 \ub3d9\uc77c\ud55c \u03b2 distribution\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.\\n- Meta-ACON\uc5d0\uc11c\ub294 7\uac1c\uc758 sample\uc774 \uc11c\ub85c \ub2e4\ub978 \u03b2 distribution\uc744 \ubcf4\uc5ec\uc8fc\uac8c \ub429\ub2c8\ub2e4. \uc5ec\uae30\uc11c \u03b2 \uac12\uc774 \uc791\uc744\uc218\ub85d, \uc120\ud615\uc801\uc73c\ub85c(linear) \ubc18\uc751\ud558\ub294 \uac83\uc774\uace0, \u03b2 \uac12\uc774 \ud074 \uc218\ub85d \ube44\uc120\ud615\uc801(non-linear)\uc73c\ub85c \ubc18\uc751\ud558\uace0 \uc788\ub294 \uac83\uc785\ub2c8\ub2e4.\\n\\nCode Snippet\uc73c\ub85c \ubcf4\uba74 \uc544\ub798\uc640 \uac19\uc2b5\ub2c8\ub2e4. \ubcf8 Snippet\uc740 \uc800\uc790\uc758 [official github](https://github.com/nmaac/acon)\uc5d0\uc11c \ubc1c\ucdcc\ud588\uc73c\uba70, \ud574\ub2f9 Repository\uc5d0\uc11c \uc790\uc138\ud55c \ucf54\ub4dc\ub97c \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n<script src=\\"https://gist.github.com/deepkyu/1616637a06e1b00534a7557c35ad2209.js\\"><\/script>\\n<script src=\\"https://gist.github.com/deepkyu/77b2e5acd98969fdb21ea22198954ad5.js\\"><\/script>\\n\\n### \uacb0\uacfc\\n\\n| ImageNet Classification Result                      | Accuracy Improvements                                 |\\n| --------------------------------------------------- | ----------------------------------------------------- |\\n| ![figure9_result1.png](./image/figure9_result1.png) | ![figure10_result2.png](./image/figure10_result2.png) |\\n\\nImageNet Classification\uc5d0 \ub300\ud55c ShuffleNetV2 \uae30\uc900 \uacb0\uacfc\ub97c \uc0b4\ud3b4\ubcf4\uba74, \ud559\uc2b5 \uc18d\ub3c4\ub3c4 \ube60\ub97c \ubfd0\ub354\ub7ec, Meta-ACON\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c Error rate\uac00 \ub0ae\uc544\uc9c0\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub610\ud55c, \uc804\ubc18\uc801\uc73c\ub85c \ubaa8\ub378 \uc0ac\uc774\uc988\uac00 \ucee4\uc9c8 \uc218\ub85d, Meta-ACON\uc744 \uc0ac\uc6a9\ud560 \uc218\ub85d Accuracy \ud5a5\uc0c1\uc774 \ud07d\ub2c8\ub2e4. (Swish \ub300\uccb4, SENet Novelty \ucd94\uac00 \ub4f1 \ub300\ube44)\\n\\n<img className={clsx(styles.figCenter, styles.medium)} src={figResultFour} alt=\\"figure12_result4\\" />\\n<img className={clsx(styles.figCenter, styles.medium)} src={figResultFive} alt=\\"figure13_result5\\" />\\n\\n\uc774\ub807\uac8c Meta-ACON\uc740 \ub2e4\ub978 activation \ub300\ube44 ImageNet Classification\uc5d0\uc11c \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\uace0 \uc788\uc2b5\ub2c8\ub2e4. \ub610\ud55c, \uc81c\ud55c\uc801\uc774\uae30\ub294 \ud558\ub098, \ud2b9\uc815 backbone\uc5d0 \ub300\ud574\uc11c Object Detection \ubc0f Semantic Segmentation\uc5d0 \uc788\uc5b4\uc11c\ub3c4 \ub2e4\ub978 activation function\uc744 \uc0ac\uc6a9\ud560 \ub54c\ubcf4\ub2e4 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\\n\\n### \ub9c8\ubb34\ub9ac\\n\\n\uc774\ub807\uac8c \uc624\ub298\uc740 ReLU\uc640 Swish \uac04\uc758 \uad00\uacc4\ub97c \ud1b5\ud574 \uc0c8\ub85c\uc6b4 Activation Function\ub4e4\uc774 \ud3ec\uc9c4\ub418\uc5b4 \uc788\uc744\ub9cc\ud55c \uc77c\ubc18\ud654\ub41c \uc2dd\uc744 \ucc3e\uace0(ACON Family), \uc774\ub97c \uae30\ubc18\uc73c\ub85c Trainable\ud55c Activation Function\uc744 \uc0c8\ub85c \ub9cc\ub098\ubcfc \uc218 \uc788\uc5c8\uc2b5\ub2c8\ub2e4.  \\n\uc0ac\uc2e4 \uc774\ub807\uac8c \ud6c8\ub828 \uac00\ub2a5\ud55c \ud30c\ub77c\ubbf8\ud130\ub97c \uac00\uc9c4 Activation Function\uc774 ACON\ub9cc \ucc98\uc74c\uc778 \uac83\uc740 \uc544\ub2d9\ub2c8\ub2e4. \ub610\ud55c, \uc5ec\ub7ec Sub-task\uc5d0 \ub300\ud574 \ubc94\uc6a9\uc801\uc73c\ub85c \uc0ac\uc6a9\ub420 \uc218 \uc788\ub294 Activation Function\uc77c\uc9c0\ub294 \ubbf8\uc9c0\uc218\uc774\uae30\ub3c4 \ud558\uace0\uc694. \ud2b9\ud788 \ubaa8\ub378 \uacbd\ub7c9\ud654 \ub4f1 \uc5b4\ub290 \ud55c\ud3b8\uc5d0\uc11c\ub294 Non-linear Activation Function\ub9c8\uc800 Bottleneck\uc73c\ub85c \uc9da\uace0 \ub118\uc5b4\uac00\ub294 \uc2e4\uc815\uc774\uae30\uc5d0[<sup>[3]</sup>](#r3), \ubaa8\ub4e0 \ubaa9\uc801\uc744 \ub9cc\uc871\uc2dc\ud0ac\ub9cc\ud55c \uc0c8\ub85c\uc6b4 \ud65c\uc131 \ud568\uc218\ub97c \ucc3e\uc740 \uc5f0\uad6c\ub294 \uc544\ub2d9\ub2c8\ub2e4. \ub2e4\ub9cc, \uc2dd\uc5d0 \ub300\ud55c \uac04\ub2e8\ud55c \uc815\ub9ac\ub85c ReLU\uc640 Swish \uac04\uc758 \uad00\uacc4\ub97c \ubcf4\uc784\uacfc \ub3d9\uc2dc\uc5d0, \uc0c8\ub85c\uc6b4 Activation Family\ub97c \uc81c\uc2dc\ud588\ub2e4\ub294 \ub370\uc5d0 \uc758\uc758\uac00 \uc788\ub294 \ub17c\ubb38\uc774\uc5c8\uc2b5\ub2c8\ub2e4.\\n\\nCVPR 2021\uc5d0\uc11c \uc774\ub7ec\ud55c \ub17c\ubb38\ub3c4 \ubc1c\ud45c\ub41c\ub2e4\ub294 \uac83\uc744 \ud568\uaed8 \uacf5\uc720\ud558\uace0 \uc2f6\uc5b4 \uac04\ub7b5\ud558\uac8c\ub098\ub9c8 \ub9ac\ubdf0\ub97c \uc9c4\ud589\ud574\ubd24\uc2b5\ub2c8\ub2e4 :+1:\\n\\n\\n### References (+ \ud568\uaed8 \uc77d\uc73c\uba74 \uc88b\uc740 \ub17c\ubb38\ub4e4)\\n\\n<a name=\\"r1\\"></a>\\n\\n1. Ramachandran, Prajit, Barret Zoph, and Quoc V. Le. \\"Searching for activation functions.\\" arXiv preprint arXiv:1710.05941 (2017). [[paper]](https://arxiv.org/abs/1710.05941) \\n\\n<a name=\\"r2\\"></a>\\n\\n2. Goodfellow, Ian, et al. \\"Maxout networks.\\" International conference on machine learning. PMLR, 2013. [[paper]](http://proceedings.mlr.press/v28/goodfellow13.html)\\n\\n<a name=\\"r3\\"></a>\\n\\n3. Han Cai, Chuang Gan, Ligeng Zhu, and Song Han. \\"TinyTL: Reduce Memory, Not Parameters for Efficient On-Device Learning\\n.\\" Part of Advances in Neural Information Processing Systems 33 (NeurIPS 2020) [[paper]](https://proceedings.neurips.cc//paper_files/paper/2020/hash/81f7acabd411274fcf65ce2070ed568a-Abstract.html)\\n\\n\\n\\n### TL;DR\\n\\n- Activation function\ub4e4\uc5d0 \ub300\ud574 \uae30\uc874 Maxout family\uc5d0 \ud574\ub2f9\ud558\ub294 \uc77c\ubc18\ud654\ub97c \ub118\uc5b4 **ACON Family**\ub77c\ub294 \uac1c\ub150\uc73c\ub85c \ud655\uc7a5\ud558\uc5ec \uc77c\ubc18\ud654\ub97c \ud569\ub2c8\ub2e4.\\n- \uc774\ub97c \ud1b5\ud574 ACON Family\uc5d0\uc11c \uac01 activation\uc744 \uacb0\uc815 \uc9d3\ub294 parameter \uc790\uccb4\ub97c learnable\ud558\uac8c \ud558\uc5ec **acon** \uc774\ub77c\ub294 activation\uc744 \uc0c8\ub86d\uac8c \uc81c\uc2dc\ud569\ub2c8\ub2e4.\\n- \uae30\uc874 Swish \ub294 NAS\ub85c \ucc3e\uc740 activation\uc73c\ub85c\uc11c, \ub354 \uc88b\ub2e4\ub294 \uac83\ub9cc \uc54c \ubfd0, \uc65c \uc88b\uc740\uc9c0\ub97c \ubab0\ub790\ub294\ub370, **ACON Family**\uc5d0 \ub300\uc751\ud558\uc5ec \ubd24\uc744 \ub54c, \uc774\ub97c \uc5b4\ub290\uc815\ub3c4 \uc124\uba85\ud560 \uc218 \uc788\uac8c \ub429\ub2c8\ub2e4."},{"id":"diffaugment","metadata":{"permalink":"/papers/diffaugment","source":"@site/papers/2021-05-03-paper-review-diffaugment/index.mdx","title":"Differentiable Augmentation for Data-Efficient GAN Training","description":"\uc801\uc740 \ub370\uc774\ud130\ub85c \ud6a8\uc728\uc801\uc73c\ub85c GAN \ud559\uc2b5\ud558\ub294 \ubc29\ubc95\uc744 \ud655\uc778\ud574\ubd05\ub2c8\ub2e4.","date":"2021-05-03T00:00:00.000Z","formattedDate":"May 3, 2021","tags":[{"label":"paper-review","permalink":"/papers/tags/paper-review"},{"label":"gan","permalink":"/papers/tags/gan"}],"readingTime":6.855,"truncated":false,"authors":[{"name":"Hyoung-Kyu Song","title":"AI Researcher (Vision)","url":"https://github.com/deepkyu","imageURL":"https://github.com/deepkyu.png","key":"hkyu"}],"frontMatter":{"slug":"diffaugment","title":"Differentiable Augmentation for Data-Efficient GAN Training","description":"\uc801\uc740 \ub370\uc774\ud130\ub85c \ud6a8\uc728\uc801\uc73c\ub85c GAN \ud559\uc2b5\ud558\ub294 \ubc29\ubc95\uc744 \ud655\uc778\ud574\ubd05\ub2c8\ub2e4.","image":"img/default.png","authors":["hkyu"],"tags":["paper-review","gan"]},"prevItem":{"title":"Activate or Not: Learning Customized Activation","permalink":"/papers/acon"},"nextItem":{"title":"FreezeD: a Simple Baseline for Fine-tuning GANs","permalink":"/papers/freezed"}},"content":"import clsx from \'clsx\';\\nimport styles from \'../blog.module.css\';\\n\\nimport figAblation from \'./image/ablation_augmentation.png\';\\nimport figAugResult from \'./image/augmentation_type_result.png\';\\nimport figAugType from \'./image/augmentation_type.png\';\\nimport figOverfitting from \'./image/d_overfitting.png\';\\nimport figInterpolation from \'./image/interpolation.png\';\\nimport figModelSize from \'./image/model_size_fid.png\';\\nimport figReg from \'./image/r1_regularization.png\';\\nimport figResultCompare from \'./image/result_compare.png\';\\nimport figTrainingMethod from \'./image/training_method.png\';\\nimport figVsStylegan from \'./image/vs_stylegan2.png\';\\n\\n[![arXiv](https://img.shields.io/badge/arXiv-2006.10738-brightgreen.svg?style=flat-square)](https://arxiv.org/abs/2006.10738)\\n[![githubio](https://img.shields.io/static/v1?message=Official%20Repo&logo=Github&labelColor=grey&color=blue&logoColor=white&label=%20&style=flat-square)](https://github.com/mit-han-lab/data-efficient-gans)\\n\\n> Zhao, Shengyu, et al. \\"Differentiable augmentation for data-efficient gan training.\\"  \\n> Advances in Neural Information Processing Systems 33 (2020): 7559-7570.\\n\\n\ucc38\uace0\ub85c Song Han \uc5f0\uad6c\uc2e4\uc740 Neural Network Compression \ubd84\uc57c\uc5d0 \uc788\uc5b4 Top\uc744 \ub2ec\ub9ac\uace0 \uc788\ub294 \uc5f0\uad6c\uc2e4\uc774\ub2e4. \ud6c4\uc5d0 \uc18c\uac1c\ud560 AnycostGAN\uc5d0\uc11c\ub3c4 DiffAugment\uac00 \uc5b8\uae09\uc774 \ub41c\ub2e4.\\n\\nHan Lab\uc740 \uae30\uc874\uc5d0\ub294 \ubc29\ubc95\ub860\uc5d0 \uc788\uc5b4 Network Pruning, KD(Knowledge Distillation) \ub4f1\uc5d0 \uc9d1\uc911\uc744 \ud588\uace0, TinyTL \ub4f1 Activation\uc5d0 \ub300\ud55c \uacbd\ub7c9\ud654\ub3c4 \uc5f0\uad6c\ub97c \uc9c4\ud589\ud588\ub2e4. \ub2e4\ub9cc, \ub300\ubd80\ubd84 Task\uac00 Image Recognition\uc5d0 \uad6d\ud55c\ub418\uc5b4 \uc788\uc5c8\ub2e4. Song Han\uc740 CVPR2020\uc5d0\uc11c GAN Compression\uc774\ub77c\ub294 \ub17c\ubb38\uc744 \ud1b5\ud574 Image Generation\uc5d0 \ub300\ud55c Compression \ub17c\ubb38\uc744 \uc2dc\uc791\uc73c\ub85c, GAN \uad00\ub828 \uc5f0\uad6c\ub97c \uc9c0\uc18d\ud574\uc11c \uc774\uc5b4\uc624\uace0 \uc788\ub2e4. \\n\\n## \ubc30\uacbd \uc9c0\uc2dd\\n\\n### \uae30\uc874\uc758 Regularization\\n\\nGAN Training \uc790\uccb4\uac00 \uad49\uc7a5\ud788 Unstable\ud55c Process\uc774\uae30 \ub54c\ubb38\uc5d0, \ucd94\uac00\uc801\uc778 Regularization\uc774 \ub9ce\uc774 \ud544\uc694\ud558\ub2e4. \uc9c0\uae08\uae4c\uc9c0 \uc5ec\ub7ec\uac00\uc9c0 Regularization \ubc29\uc2dd\ub4e4\uc774 \ub4f1\uc7a5\ud588\ub2e4.\\n\\n- Instance Noise\\n- Jensen-Shannon Regularization\\n- Gradient Penalty\\n- Spectral Normalization\\n- Adversarial Defense Regularization\\n- Consistency Regularization\\n\\n\uc774\ub7ec\ud55c Regularization Method\ub4e4\uc740 Input \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud574 \ub300\uc751\ud558\ub294 \uac83\uc774\uc9c0, augmentation\uc5d0 \ub300\ud574 \uc18c\ud654\ud560 \uc218 \uc788\ub294 \ubc29\ubc95\ub4e4\uc774 \uc544\ub2c8\ub2e4.\\n\\n\uc800\uc790\ub294 \uc5ec\ub7ec \uac00\uc9c0 Augmentation\uc5d0 \ub300\ud574\uc11c\ub3c4 \uc798 working \ud558\ub294 Discriminator\ub97c \uad6c\ucd95\ud558\uace0\uc790 \ud588\ub2e4.\\n\\n### D\ub294 \uc9c0\uae08\uae4c\uc9c0 Overfitting \ud574\uc654\ub2e4\\n\\n<img className={styles.figCenter} src={figOverfitting} alt=\\"d_overfitting\\" />\\n\\nBigGAN\uc744 \uc801\uc740 \ub370\uc774\ud130\uc5d0 \ub300\ud574 \ud559\uc2b5\ud588\uc744 \ub54c, \ud559\uc2b5\uc744 \ud558\ub2e4\uac00 collapse\ud558\ub294 \uac78 \ubcf4\uc5ec\uc8fc\ub294 Figure\ub2e4. \uc67c\ucabd\uc5d0\uc11c \ubcf4\uba74 \ube68\uac04\uc0c9(CIFAR-10 10%\ub9cc \uac00\uc9c0\uace0 \ud559\uc2b5) \uadf8\ub798\ud504\uac00 \ud280\uc5b4\ubc84\ub9ac\ub294 \uac78 \ubcfc \uc218 \uc788\ub2e4. \uc774\uac8c \uc65c \uadf8\ub7f4\uae4c \ud558\uace0 Discriminator\ub97c \ubcf4\uba74, \uc544\ub2c8\ub098 \ub2e4\ub97c\uae4c Training Accuracy\uac00 \ube60\ub974\uac8c \ud559\uc2b5\uc774 \ub3fc\uc11c \uadf8\ub807\ub2e4.\\n\\n\uadf8\ub7f0\ub370 D\uc5d0 \ub300\ud574 \uac01 Iteration\uc5d0 \ub300\ud55c Validation Acc.\ub97c \uce21\uc815\ud574\ubcf4\uba74, mode collapse\uac00 \ub418\uc5c8\ub2e4\ub294 \uac78 \ubcfc \uc218 \uc788\ub2e4. \uc989, D\uac00 training set \uc744 memorize \ud574\uc654\uace0, \uc774\ub85c \uc778\ud574 generalize\uac00 \uc548\ub410\ub2e4\ub294 \uac78 \ubcf4\uc5ec\uc900\ub2e4.\\n\\n## Training Method\\n\\n<img className={clsx(styles.figCenter, styles.medium)} src={figTrainingMethod} alt=\\"training_method\\" />\\n\\nDiffAugment\uc758 \ud559\uc2b5 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub9bc.\\n\\n\uc6d0\ubcf8 \uc774\ubbf8\uc9c0(x), \uc0dd\uc131\ud55c \uc774\ubbf8\uc9c0(G(z)) \ubaa8\ub450\uc5d0 augmentation(T)\uc744 \uc801\uc6a9\ud55c\ub2e4.\\n\\nAugmentation Senario\uc5d0 \ub530\ub77c\uc11c \uc5ec\ub7ec \uac00\uc9c0 Case\ub85c \ub098\ub20c \uc218 \uc788\ub2e4.\\n\\nAugment Reals Only: Real \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud574\ub9cc Augmentation\uc744 \uc9c4\ud589\ud568 (i\ub9cc \uc9c4\ud589.)\\n\u2192 Augmentation \ud55c \uac78 \uadf8\ub300\ub85c \ubaa8\ubc29\ud558\uc5ec \uc0dd\uc131\ud55c\ub2e4.\\n\\nAugment D Only: Discriminator\uc5d0 \ub123\ub294 Input\ub4e4\uc5d0 \ub300\ud574 \uc9c4\ud589\ud568 (i, ii \ub9cc \uc9c4\ud589. iii\ub294 \uadf8\ub300\ub85c)\\n\u2192 Unbalanced Optimization \uc5d0 \uc758\ud574 Diverge \ud574\ubc84\ub9b0\ub2e4.\\n\\nD perfectly classifies the augmented images (both T(x) and T(G(z)) but barely\\nrecognizes G(z) (i.e., fake images without augmentation)\\n\uc774 \ub54c\ubb38\uc5d0 G\uc758 gradient update\ub97c \ud560 \ub54c, Discriminator\uac00 \uc798 working \ud558\uc9c0 \ubabb\ud558\uba74\uc11c, G\uc5d0 \ub300\ud55c \ud559\uc2b5\uc5d0 \ubc29\ud574\uac00 \ub428.\\n\\n## Result\\n\\n### StyleGAN2\uc640 \ube44\uad50\\n\\n<img className={styles.figCenter} src={figVsStylegan} alt=\\"vs_stylegan2\\" />\\n\\n\uae30\uc874 StyleGAN2\uacfc \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ud558\ub294 DiffAugment\ub97c \uc801\uc6a9\ud588\uc744 \ub54c\ub97c \ube44\uad50\ud558\ub294 Figure.  \\nStyleGAN2\ub294 \ub370\uc774\ud130\uac00 \uc791\uc544\uc9c8\uc218\ub85d, FID, IS \uac12\uc758 \ubcc0\ud654\uac00 dramatic\ud55c\ub370, DiffAugment\ub294 \uc0c1\ub300\uc801\uc73c\ub85c \uc801\uc740 \ub370\uc774\ud130\uc5d0 \ub300\ud574\uc11c\ub3c4 generalize\ub418\uc5b4 \uc788\ub2e4\ub294 \uac78 \ubcfc \uc218 \uc788\ub2e4. StyleGAN2\uac00 \uc791\uc740 \ub370\uc774\ud130\uc5d0 generalize\uac00 \uc548\ub41c\ub2e4\ub294 \uac74 \uc880 \uc54c\ub824\uc9c4 \uc0ac\uc2e4\uc774\uc5c8\uc73c\ub2c8, Discriminator Training Method\uc5d0 \uc9d1\uc911\ud55c ADA\ub098 Freeze D\uc640 \ube44\uad50\ud558\ub294 Figure\ub97c \uc790\uc5f0\uc2a4\ub7fd\uac8c \uae30\ub300\ud558\uac8c \ub41c\ub2e4.\\n\\n### Low-Shot Generation\\n\\n<img className={styles.figCenter} src={figResultCompare} alt=\\"result_compare\\" />\\n\\nLow-shot generation without pre-training.\\n\\n\uac01\uac01 \uc624\ubc14\ub9c8 100\uc7a5, \uace0\uc591\uc774 160\uc7a5, \uac15\uc544\uc9c0 389\uc7a5\ub9cc\uc744 \uac00\uc9c0\uace0 \ud559\uc2b5\uc744 \ud558\uc5ec \uc0dd\uc131\ud574\ub0b8 \uc774\ubbf8\uc9c0\ub4e4\uc774\ub2e4. (w/o pre-training)\\n\\n## Result\\n\\n### Training Performance\\n\\n<img className={styles.figCenter} src={figAugResult} alt=\\"augmentation_type_result\\" />\\n\\nAugmentation \uc870\ud569\uc5d0 \ub530\ub77c \ub2ec\ub77c\uc9c0\ub294 DiffAugment Training Performance (CIFAR-10 Data 100% \uc0ac\uc6a9)\\n\\nBigGAN \ub300\ube44 Discriminator\uac00 Validation\uc5d0 \uc788\uc5b4\uc11c\ub3c4 generalize \ud558\uc5ec \ud559\uc2b5\ub418\uc5c8\ub2e4\uace0 \ubcfc \uc218 \uc788\ub2e4. DiffAugment \uc790\uccb4\ub294 Low Dataset\uc5d0 \ub300\ud574\uc11c\ub3c4 Generation\uc744 \uc548\uc815\uc801\uc73c\ub85c \ud560 \uc218 \uc788\ub2e4\ub294 Novelty\ub97c \uac00\uc9c0\uace0 \uc788\uc9c0\ub9cc, \ubcf8 Figure\ub294 BigGAN\ub3c4 \ud559\uc2b5\ud588\ub2e4\uace0 \ud558\ub294 \ub370\uc774\ud130\uac00 CIFAR-10 \uc804\uccb4\ub97c \uc0ac\uc6a9\ud55c \uac83\uc774\uc5c8\uc73c\ub2c8, \ud574\ub2f9 \uc870\uac74\uc73c\ub85c Comparison\uc744 \ud55c \uac83\uc73c\ub85c \ud574\uc11d\ud560 \uc218 \uc788\ub2e4.\\n\\n### Interpolation\ub3c4 \uac00\ub2a5\ud558\ub2e4\\n\\n<img className={styles.figCenter} src={figInterpolation} alt=\\"interpolation\\" />\\n\\nStyle Space\uc5d0\uc11c Interpolation\uc774 \uac00\ub2a5\ud568\uc744 \ubcf4\uc5ec\uc8fc\ub294 Figure.\\n\\n\uc801\uc740 \ub370\uc774\ud130\uc600\uc9c0\ub9cc (\uc624\ubc14\ub9c8, \uace0\uc591\uc774, \uac15\uc544\uc9c0 \ucc38\uc870), Interpolation\uc774 \uac00\ub2a5\ud560 \uc815\ub3c4\ub85c generalize\ud558\uac8c \ud559\uc2b5\uc774 \ub418\uc5c8\ub2e4.\\n\\n### Model Size\uc5d0 \ub300\ud55c \ubd84\uc11d\\n\\n<img className={styles.figCenter} src={figModelSize} alt=\\"model_size_fid\\" />\\n\\nModel size\uac00 FID\uc5d0 \uc5bc\ub9c8\ub098 \uc601\ud5a5\uc744 \uc8fc\ub294\uac00\uc5d0 \ub300\ud55c Figure\\n\\nCIFAR-10 \ub370\uc774\ud130 10%\uc5d0 \ub300\ud574\uc11c\ub9cc \ud559\uc2b5\uc744 \ud588\uc744 \ub54c, generalize\uac00 \ub420 \uc218 \uc788\ub294 \uac00\ub97c \ub2e4\ub8ec \ubd80\ubd84\uc774\ub2e4. BigGAN \ub300\ube44 channel size\ub97c \uc904\uc5ec\uac00\uba70 \ube44\uad50\ub97c \ud574\ubd10\ub3c4, \uc5b4\ub5a4 capacity\ub4e0 \uc0c1\uad00\uc5c6\uc774 \ub354 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc900\ub2e4. StyleGAN2\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 R1 Regularization \uad00\ub828\ud574\uc11c\ub3c4, hyperparameter\uac00 \ub3d9\uc77c\ud55c \uc138\ud305\uc77c \ub54c \ub354 \ub098\uc740 FID\ub97c \ubcf4\uc5ec\uc92c\ub2e4.\\n\\n### Regularization\\n\\n:::tip\\n\\n**R1 Regularization**  \\nGradient Penalty\ub85c regularize \ud558\ub294 \ubc29\uc2dd\uc73c\ub85c, Discriminator\uc758 Real Data\uc5d0 \ub300\ud574 Penalize\ub97c \uc900\ub2e4.\\n\\n$$\\nR_{1}(\\\\psi):=\\\\frac{\\\\gamma}{2} \\\\mathrm{E}_{p_{\\\\mathcal{D}}(x)}\\\\left[\\\\left\\\\|\\\\nabla D_{\\\\psi}(x)\\\\right\\\\|^{2}\\\\right]\\n$$\\n\\n> when the generator distribution produces the true data distribution and the discriminator is equal to 0 on the data manifold, the gradient penalty ensures that the discriminator cannot create a non-zero gradient orthogonal to the data manifold without suffering a loss in the GAN game.\\n\\n:::\\n\\n### Ablation for Augmentation\\n\\n<img className={styles.figCenter} src={figAblation} alt=\\"ablation_augmentation\\" />\\n\\n\uc5ec\ub7ec \uac00\uc9c0 Augmentation\uc5d0 \ub300\ud574 FID\ub97c \ud655\uc778\ud574\ubcf8 \uacb0\uacfc\ub2e4.\\nAblation\uc744 \uc9c4\ud589\ud55c \ub05d\uc5d0, color distortion, translation, cutout\ub9cc \uc900 \uac83\uc73c\ub85c \ud655\uc778\ud588\ub2e4. (\uba3c\uc800 \uc0dd\uac01\ud558\uace0 \uc900 \uac74 \uc544\ub2cc \uac83\uc73c\ub85c \ud655\uc778\ud588\ub2e4.)\\nStyleGAN2\uc758 FID\uc774\uace0, CIFAR-10 10% \ub370\uc774\ud130\ub9cc\uc744 \uac00\uc9c0\uace0 Training \ud588\uc744 \ub54c\uc758 \uacb0\uacfc\ub2e4."},{"id":"freezed","metadata":{"permalink":"/papers/freezed","source":"@site/papers/2020-09-24-paper-review-freezed/index.mdx","title":"FreezeD: a Simple Baseline for Fine-tuning GANs","description":"GAN Finetuning \uc2dc\uc5d0 Discriminator\ub97c Freezing \ud558\uba74 \uc5b4\ub5bb\uac8c \ub420\uae4c\uc694?","date":"2020-09-24T00:00:00.000Z","formattedDate":"September 24, 2020","tags":[{"label":"paper-review","permalink":"/papers/tags/paper-review"},{"label":"gan","permalink":"/papers/tags/gan"}],"readingTime":7.665,"truncated":false,"authors":[{"name":"Hyoung-Kyu Song","title":"AI Researcher (Vision)","url":"https://github.com/deepkyu","imageURL":"https://github.com/deepkyu.png","key":"hkyu"}],"frontMatter":{"slug":"freezed","title":"FreezeD: a Simple Baseline for Fine-tuning GANs","description":"GAN Finetuning \uc2dc\uc5d0 Discriminator\ub97c Freezing \ud558\uba74 \uc5b4\ub5bb\uac8c \ub420\uae4c\uc694?","image":"img/default.png","authors":["hkyu"],"tags":["paper-review","gan"]},"prevItem":{"title":"Differentiable Augmentation for Data-Efficient GAN Training","permalink":"/papers/diffaugment"}},"content":"import clsx from \'clsx\';\\nimport styles from \'../blog.module.css\';\\n\\nimport figGraph from \'./image/result_graph.png\';\\nimport figTable from \'./image/table.png\';\\n\\n[![arXiv](https://img.shields.io/badge/arXiv-2002.10964-brightgreen.svg?style=flat-square)](https://arxiv.org/abs/2002.10964)\\n[![githubio](https://img.shields.io/static/v1?message=Official%20Repo&logo=Github&labelColor=grey&color=blue&logoColor=white&label=%20&style=flat-square)](https://github.com/sangwoomo/FreezeD)\\n\\n> Mo, Sangwoo, et al. \\"Freeze the discriminator: a simple baseline for fine-tuning gans.\\"  \\n> CVPR AI for Content Creation Workshop (2020).\\n\\n\\n## Contribution\\n\\nGAN\uc744\xa0fine-tuning\ud558\ub294\xa0\ub370\uc5d0\xa0\uc788\uc5b4, discriminator\uc758\xa0lower layer\ub4e4(classifier\xa0\ub9d0\uace0\xa0visul repr. (=visual feature) extractor)\uc5d0 \ub300\ud574\xa0freeze\ud558\uace0\xa0G/D\uc5d0\xa0\ub300\ud574\xa0fine-tuning\uc744\xa0\uc9c4\ud589\ud558\uba74, limited data\ub85c\xa0\ud6a8\uacfc\uc801\uc778\xa0transfer learning\uc744\xa0\ud560\xa0\uc218\xa0\uc788\ub2e4.\\n\\n\uc989, image classification \ub4f1 recognition(\ub610\ub294 understanding)\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 fine-tuning \ubc29\uc2dd (visual representation\uc740 freeze, classifier\ub9cc use_gradient)\uc774 GAN \ubaa8\ub378\uc5d0\uc11c\ub3c4 \uc720\uc6a9\ud558\uac8c \uc0ac\uc6a9\ub420 \uc218 \uc788\ub2e4.\\n\\n<img className={styles.figCenter} src={figGraph} alt=\\"result_graph\\" />\\n\\n## Background\\n\\n\ucd5c\uadfc\xa0SotA GAN\ub4e4\uc740\xa0\ub9ce\uc740\xa0\uc591\uc758\xa0training data\ub97c\xa0\uc694\uad6c\ud560\xa0\ubfd0\ub9cc\xa0\uc544\ub2c8\ub77c,\xa0\ub9e4\uc6b0\xa0\ud070 computational resource\ub97c\xa0\uc694\uad6c\ud558\ub294\xa0\uacbd\uc6b0\uac00\xa0\ub9ce\uc544,\xa0\uc2e4\uc9c8\uc801\uc778\xa0senario\uc5d0\xa0\ub300\uc785\ud558\ub294\xa0\ub370\uc5d0\xa0\uc5b4\ub824\uc6c0\uc774\xa0\ub9ce\ub2e4.\\n\\n\uadf8\ub798\uc11c\xa0\uc774\ub97c\xa0\ud574\uacb0\ud558\uace0\uc790\xa0\ub9ce\uc740\xa0\uc811\uadfc\ubc95\ub4e4\uc774\xa0recogntion task\uc5d0\uc11c\uc758\xa0\uc131\uacf5\uc801\uc778\xa0\uc0ac\ub840\ub4e4\uc744\xa0\ubc14\ud0d5\uc73c\ub85c\xa0GAN\uc5d0\uc11c\uc758\xa0transfer learning\uc744\xa0\uc2dc\ub3c4\ud558\uace0\xa0\uc788\uace0,\xa0\uc774\ub97c\xa0\ud1b5\ud574\xa0\ud55c\uc815\ub41c\xa0\ub370\uc774\ud130\ub97c\xa0\uac00\uc9c0\uace0 image generation\xa0\ud558\ub294\xa0\ubc29\ubc95\ub4e4\uc744\xa0\uc5f0\uad6c\ud558\uace0\xa0\uc788\ub2e4.\\n\\n\ud558\uc9c0\ub9cc\xa0\ud604\uc7ac\uae4c\uc9c0\xa0Transfer Learning\uc744\xa0\uc9c4\ud589\ud55c\xa0\ub9ce\uc740\xa0\uc0ac\ub840\ub4e4\uc774\xa0\ud55c\uc815\ub41c\xa0training data\ub85c\xa0\uc9c4\ud589\ud588\uc744\xa0\ub54c, overfitting\uc774\xa0\ub418\ub294\xa0\uacbd\uc6b0\uac00\ub9ce\uc558\uace0,\xa0\ud2b9\ud788\xa0dataset\uc758\xa0distribution\uc774\xa0pre-training\uc744\xa0\ud560\xa0\ub54c\xa0\uc0ac\uc6a9\ud55c\xa0large dataset\uacfc\xa0\ub9ce\uc774\xa0\ub2e4\ub97c\xa0\uacbd\uc6b0, robust\ud558\uc9c0\xa0\ubabb\ud558\ub294\xa0\uc77c\uc774\xa0\ub9ce\uc558\ub2e4 (not robust in learning a significant distribution shift).\\n\\n### Previous Methods for GAN transfer learning\\n\\n\uc6b0\uc120 \uae30\uc874\uc758 GAN Finetuning\uc73c\ub85c \uc2dc\ub3c4\ub41c \ubc29\uc2dd\uc740 \uc544\ub798\uc640 \uac19\uc774 \ub098\uc5f4\ud560 \uc218 \uc788\ub2e4.\\n\\n#### Fine-tuning\\n\\nTarget Model(=limited data\uc5d0 \ub300\ud55c model)\uc758 generator\uc640 discriminator \uac01\uac01\uc5d0 \ub300\ud574 Source Model(=trained with large dataset)\uc758 pre-trained weight\ub97c load\ud558\uc5ec, \ud574\ub2f9 checkpoint\ubd80\ud130 training\uc744 \uc9c4\ud589\ud55c\ub2e4.\\n\\n\ud558\uc9c0\ub9cc, \uc774\ub7ec\ud55c fine-tuning \ubc29\uc2dd\uc740 overfit\ub418\ub294 \ubb38\uc81c\uc810\uc744 \ud56d\uc0c1 \uac00\uc9c0\uace0 \uc788\uace0, \uc774\ub97c \uc704\ud574 \uc801\uc808\ud55c regularization\uc774 \ub9e4\ubc88 \ud544\uc694\ud558\ub2e4.\\n\\n#### Scale/Shift\\n\\n\uc704\uc640 \uac19\uc740 naive fine-tuning\uc774 overfit\uc5d0 \ube60\uc9c0\uae30 \uc27d\ub2e4\ub294 \ub2e8\uc810\uc774 \uc788\uae30\uc5d0, scale + shift\ub294 \ub2e4\ub978 weight\ub294 \uadf8\ub300\ub85c \ub194\ub450\uace0 batchnorm \ub4f1 normalization layer\ub9cc update\ud558\ub294 \ubc29\uc2dd\uc73c\ub85c \uc774\ub97c \uc9c4\ud589\ud558\uace0\uc790 \uc2dc\ub3c4\ud588\ub2e4. \ud558\uc9c0\ub9cc, \uc774\ub294 restriction\uc774 \uba85\ud655\ud574\uc11c \uadf8\ub9ac \uc88b\uc740 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\uc9c0 \uc54a\uc558\uace0, \ud2b9\ud788 source dataset(=large dataset)\uacfc target dataset(=limited dataset) \uac04 distribution shift\uac00 \uadf9\uba85\ud560 \uacbd\uc6b0, \uacb0\uacfc\uac00 \ub354\uc6b1 \uc548 \uc88b\uac8c \ub098\uc654\ub2e4.\\n\\n#### Generative latent optimization (GLO)\\n\\nGAN loss\ub294 discriminator\ub85c\ubd80\ud130 \uc8fc\uc5b4\uc9c0\ub294 loss\uc774\ub2e4\ubcf4\ub2c8, limited data\uc5d0 reliable \ud558\uc9c0 \uc54a\ub2e4. GLO\ub294 \uc774\ub85c\ubd80\ud130 source data\ub85c \ud559\uc2b5\ud55c generator\ub9cc \ub5bc\uc5b4\ub2e4\uac00 L1 + perceptual loss\uc758 \uc870\ud569\uc73c\ub85c supervised learning \ud558\ub294 \ubc29\uc2dd\uc744 \ub9d0\ud55c\ub2e4. \uc774 \ub54c, GLO\ub294 overfitting\uc744 \ubc29\uc9c0\ud558\uae30 \uc704\ud574 generator\uc640 latent codes\ub97c \ub3d9\uc2dc\uc5d0 optimize\ud558\ub294 \ubc29\uc2dd\uc73c\ub85c \ud6c8\ub828\ud55c\ub2e4. \uc989, latent vector\uc640 sample data\uac00 \ud56d\uc0c1 1:1\ub85c \ub418\ub3c4\ub85d \ud559\uc2b5\ud55c\ub2e4.  \uc774\ub97c \ud1b5\ud574 generator\uac00 sample\ub4e4\uc5d0 \ub300\ud574 generalize \ub418\ub3c4\ub85d \ud558\ub294 \ubc29\ubc95\uc774\ub2e4.\\n\\nGLO\uac00 \uc774\ub7f0 \ubc29\ud5a5\uc73c\ub85c \ud559\uc2b5\uc744 \ud558\ub2e4 \ubcf4\ub2c8 stability\ub294 \ubcf4\uc7a5\uc774 \ub418\uc9c0\ub9cc, \uc544\ubb34\ub798\ub3c4 adversarial loss\uac00 \uc5c6\ub2e4\ubcf4\ub2c8 image generation \uacb0\uacfc\uac00 \uacb0\uad6d\uc5d0\ub294 blurry \ud574\uc9c4\ub2e4\ub294 \ub2e8\uc810\uc774 \uc788\ub2e4. \uadf8\ub807\ub2e4\uace0 Adversarial \ud558\uac8c \ubcc4\ub3c4\ub85c discrimator\ub97c \ubd99\uc77c\uc218\ub3c4 \uc788\uaca0\uc9c0\ub9cc, \uc774\ub7ec\ud55c \ubc29\ud5a5\uc73c\ub85c \uc9c4\ud589\ub420 \ub54c \uae30\ubcf8\uc801\uc73c\ub85c source data\uc5d0 \ub300\ud55c discriminator\uc758 prior knowledge\uac00 \uc544\uc608 \uc99d\ubc1c\ud574\ubc84\ub9ac\ubbc0\ub85c, \uc774 \uc5ed\uc2dc \uadf8\ub807\uac8c \ud6a8\uc728\uc801\uc774\ub77c\uace0\ub294 \ubcfc \uc218 \uc5c6\ub2e4.\\n\\n#### MineGAN\\n\\nMineGAN\uc740 generator\uc758 overfitting\uc744 \ud53c\ud558\uae30 \uc704\ud574, generator\ub97c \uc218\uc815\ud558\uc5ec latent code\ub97c \uc218\uc815\ud558\ub294 \ubc29\ubc95\uc744 \uc81c\uc2dc\ud55c\ub2e4. MineGAN\uc740 latent code \uac04 transfer\ub97c \ub2f4\ub2f9\ud558\ub294 miner(\ucc44\uad74) network\ub97c \ud559\uc2b5\uc2dc\ud0a4\ub294\ub370, \uc774\ub7ec\ud55c \ubc29\uc2dd\uc740 source\uc640 target distribution\uc774 \uacf5\uc720\ud558\uace0 \uc788\ub294 \ubc14\uac00 \uc788\uc744 \ub54c \ud6a8\uacfc\uc801\uc774\uaca0\uc9c0\ub9cc, \ub450 dataset\uac00 disjoint \ud55c \uc0c1\ud669\uc5d0\uc11c\ub294 generalize \ub420 \uc218 \uc5c6\ub2e4\ub294 \ub2e8\uc810\uc744 \uac00\uc9c0\uace0 \uc788\ub2e4.\\n\\n### Suggested Methods\\n\\n#### FreezeD\\n\\nDiscriminator\uc758 lower layer(=visual representation)\ub9cc freeze, upper layer\ub294 fine-tune. \uc800\uc790\uac00 \uc131\ub2a5\ud55c \uac83 \uc911\uc5d0 \uac00\uc7a5 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc600\uc74c.\\n\\n#### L2-SP\\n\\nFine-tuning\ud558\ub294 \ubc29\uc2dd\uc778\ub370, source model\uc758 parameter\uc640 target model\uc758 parameter\ub97c L2-norm regularize \ud558\ub294 \ubc29\uc2dd\uc73c\ub85c \uc9c4\ud589\ud558\uc5ec target model\uc774 source model\uc758 knowledge\ub85c\ubd80\ud130 \ub108\ubb34 \uba40\uc5b4\uc9c0\uc9c0 \uc54a\uac8c \ud55c\ub2e4.\\n\\n\ud558\uc9c0\ub9cc, \uc774\ub294 \uadf8\ub807\uac8c \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\uc9c0 \ubabb\ud588\ub2e4. L2-norm \ud55c\ub2e4\uace0 \ud558\uba74 \uc774 \ubc29\uc2dd\uc774 \uacb0\uad6d freezing layer\ub85c \uc120\ud0dd\ud55c layer\uc5d0\ub294 infinite weight\ub97c \uc8fc\uace0, \ub2e4\ub978 layer\uc5d0\ub294 weight\ub97c 0\uc73c\ub85c \uc8fc\ub294 \ubc29\uc2dd\uc73c\ub85c \uad73\uc5b4\uc9c0\ub294\ub370, \uc774\uac83\ubcf4\ub2e4\ub294 \uac01 Layer \uc5d0 \uc801\uc808\ud55c weight \ub97c \uc8fc\ub294 \uac83\uc774 \ub2f9\uc5f0 \uc88b\uc740 \uacb0\uacfc\ub97c \ub0bc \uac83\uc774\ub2e4.\\n\\n#### Feature Distillation\\n\\nClassifier\uc758 transfer learning\uc744 \ud560 \ub54c, \uc694\uc998 \uc81c\uc77c \ub9ce\uc774 \uc0ac\uc6a9\ud558\ub294 \ubc29\uc2dd\uc774\ub2e4.\\n\\n\uc800\uc790\ub294 source model\uacfc target model\uc744 distill \ud558\ub294 \ubc29\uc2dd\uc73c\ub85c \uc9c4\ud589\ud588\ub2e4. Computation\uc73c\ub85c \ubcf4\uba74 FreezeD\ubcf4\ub2e4 2\ubc30 \uac00\ub7c9 \uc5f0\uc0b0\ub7c9\uc774 \ub9ce\uc740\ub370, FreezeD\ub791 \ube44\uad50\ud588\uc744 \ub54c \uc6b0\uc704\ub97c \uc810\ud558\ub294 \uacbd\uc6b0\ub3c4 \uc788\uc5c8\ub2e4. \uc774 \ub17c\ubb38\uc740 FreezeD\uac00 \ucd5c\uc885\uc801\uc73c\ub85c \uc81c\uc548\ud558\ub294 method\uc774\uae30\ub294 \ud558\uc9c0\ub9cc, Feature Distillation\uc774 \ubbf8\ub798\uc5d0 \ub354 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294 \ubc29\ud5a5\uc77c \uac83\uc774\ub77c\uace0 \uc774\uc57c\uae30 \ud55c\ub2e4.\\n\\n<img className={styles.figCenter} src={figTable} alt=\\"table\\" />\\n\\n## Result\\n\\n\uc800\uc790\ub294 Unconditional GAN\uacfc Conditional GAN\uc5d0 \ubaa8\ub450 generic \ud558\uac8c \uc801\uc6a9\ub420 \uc218 \uc788\ub294 \ubc29\ubc95\uc778\uc9c0\ub97c \ud30c\uc545\ud558\uae30 \uc704\ud574, \ub450 \uac00\uc9c0 adversarial model\uc744 \ub4e4\uace0 \uc654\ub2e4. Unconditional GAN\uc73c\ub85c\ub294 stylegan, conditional GAN\uc73c\ub85c\ub294 SNGAN-projection \uc744 \uc0ac\uc6a9\ud588\ub2e4. \uadf8\ub9ac\uace0 \uce21\uc815 metric \uc73c\ub85c\ub294 FID(Frechet Inception Distance)\ub9cc\uc744 \uc0ac\uc6a9\ud588\ub2e4.\\n\\n\uac01 Dataset class \ubcc4\ub85c FID\ub97c \uac01\uac01 \uacc4\uc0b0\ud588\uace0, Fine-tuning \ud55c \uac83\uacfc FreezeD \ub450 case\uc5d0 \ub300\ud55c \uacb0\uacfc\ub9cc\uc744 \ube44\uad50\ud588\ub2e4.\\n\\nFreezeD \uac00 FID\uc5d0 \uc788\uc5b4\uc11c \ud56d\uc0c1 \uc55e\uc11c\ub294 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc92c\ub2e4.\\n\\n## \ud2b9\uc774\uc810\\n\\nStyleGAN\uc744 \uc2e4\ud5d8\ud560 \ub54c, tensorflow\ub85c \ub418\uc5b4 \uc788\ub294 \uc800\uc790 repo\uac00 \uc544\ub2c8\ub77c, unofficial pytorch repo\ub97c \uc0ac\uc6a9\ud588\ub2e4.\\n\\npytorch repo\ub3c4 \ub9ce\uc740 \uc720\uc800\ub4e4\uc774 \uc548\uc815\uc131 \uac80\uc99d\uc744 \ud558\uae30\ub294 \ud588\uc5c8\ub294\ub370, \uc774\uac78 \uc0ac\uc6a9\ud558\uc5ec \ub17c\ubb38\uc774 accept\uc774 \ub418\uc5c8\uc73c\ub2c8, \ub098\ub3c4 \uc368\ub3c4 \ub418\uaca0\ub2e4\ub294 \uc0dd\uac01\uc774 \ub4e0\ub2e4. (\uc774\ub807\uac8c guarantee \ubc1b\ub294 \ubc29\ubc95\uc774...!)"}]}')}}]);