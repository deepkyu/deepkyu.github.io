"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[723],{9945:function(n){n.exports=JSON.parse('{"blogPosts":[{"id":"acon","metadata":{"permalink":"/papers/acon","source":"@site/papers/2021-07-19-paper-review-acon/index.mdx","title":"Activate or Not: Learning Customized Activation","description":"Swish\uc640 ReLU\uc640\uc758 \uad00\uacc4\ub97c \uc124\uba85\ud558\uace0, \ud559\uc2b5\uc774 \uac00\ub2a5\ud55c \ud65c\uc131\ud568\uc218\ub97c \uc18c\uac1c\ud569\ub2c8\ub2e4.","date":"2021-07-19T00:00:00.000Z","formattedDate":"July 19, 2021","tags":[{"label":"paper-review","permalink":"/papers/tags/paper-review"}],"readingTime":14.48,"truncated":false,"authors":[{"name":"Hyoung-Kyu Song","title":"AI Researcher (Vision)","url":"https://github.com/deepkyu","imageURL":"https://github.com/deepkyu.png","key":"hkyu"}],"frontMatter":{"slug":"acon","title":"Activate or Not: Learning Customized Activation","description":"Swish\uc640 ReLU\uc640\uc758 \uad00\uacc4\ub97c \uc124\uba85\ud558\uace0, \ud559\uc2b5\uc774 \uac00\ub2a5\ud55c \ud65c\uc131\ud568\uc218\ub97c \uc18c\uac1c\ud569\ub2c8\ub2e4.","image":"img/default.png","authors":["hkyu"],"tags":["paper-review"]}},"content":"import clsx from \'clsx\';\\nimport styles from \'../blog.module.css\';\\n\\nimport figSwish from \'./image/figure1_swish.png\';\\nimport figAcon from \'./image/figure4_acon.png\';\\nimport figFamily from \'./image/figure5_maxout_family_acon_family.png\';\\nimport figExample from \'./image/figure6_acon_example.png\';\\nimport figProperty from \'./image/figure7_acon_property.png\';\\nimport figDistribution from \'./image/figure8_meta_acon_distribution.png\';\\nimport figResultFour from \'./image/figure12_result4.png\';\\nimport figResultFive from \'./image/figure13_result5.png\';\\n\\n[![arXiv](https://img.shields.io/badge/arXiv-2009.04759-brightgreen.svg?style=flat-square)](https://arxiv.org/abs/2009.04759)\\n[![githubio](https://img.shields.io/static/v1?message=Official%20Repo&logo=Github&labelColor=grey&color=blue&logoColor=white&label=%20&style=flat-square)](https://github.com/nmaac/acon)\\n\\n> Ma, Ningning, et al. \\"Activate or Not: Learning Customized Activation.\\"  \\nProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\\n\\n\\n## \uba3c\uc800 \uc54c\uba74 \uc88b\uc740 \uac83\ub4e4\\n\\n### Swish Activation Function [<sup>[1]</sup>](#r1)\\n\\n$$\\n\\\\operatorname{swish}(x):=x \\\\times \\\\sigma(\\\\beta x)=\\\\frac{x}{1+e^{-\\\\beta x}}\\n$$\\n\\n<img className={styles.figCenter} src={figSwish} alt=\\"figure1_swish\\" />\\n\\n- Linear Function\uacfc ReLU \uc0ac\uc774\uc5d0\uc11c\uc758 non-linearly interpolated activation\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\\n    - $\u03b2 = 0$ \uc77c \uacbd\uc6b0, Linear function $f(x) = x/2$ \ucc98\ub7fc \uc791\uc6a9\ud558\uac8c \ub429\ub2c8\ub2e4.\\n    - \ubc18\ub300\ub85c $\u03b2 \u2192 \u221e$\uc77c \uacbd\uc6b0, Sigmoid\uc5d0 \ud574\ub2f9\ud558\ub294 \ubd80\ubd84\uc774 0-1 activation\ucc98\ub7fc \uc791\uc6a9\ud558\uac8c \ub418\uc5b4, Swish\uac00 ReLU\ucc98\ub7fc \uc791\uc6a9\ud558\uac8c \ub429\ub2c8\ub2e4.\\n    - $\u03b2 = 1$\uc77c \uacbd\uc6b0, \uac15\ud654\ud559\uc2b5\uc5d0\uc11c \uc0ac\uc6a9\ub418\ub294 Sigmoid-weighted Linear Unit (SiL) function\ucc98\ub7fc \uc791\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n    - $\u03b2$\ub294 \uc704\uc5d0\uc11c \ubcf4\uc2e0 \uac83\ucc98\ub7fc \uc5b4\ub5a4 \uc0c1\uc218\uc77c \uc218\ub3c4 \uc788\uace0, \ubaa8\ub378\uc5d0 \ub530\ub77c\uc11c\ub294 \ud6c8\ub828 \uac00\ub2a5\ud55c \ud30c\ub77c\ubbf8\ud130\uac00 \ub420 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\\n- \ube0c\ub808\uc778\ud300 AI Scientist\ubd84\ub4e4\uc774 \uc790\uc8fc \uc0ac\uc6a9\ud558\uc2dc\ub294 Activation Function\uc774\uae30\ub3c4 \ud558\uc8e0 \ud83d\ude42\\n- Generative Model\uc5d0\uc11c\ub3c4 ReLU \ub300\uc2e0 \uc0ac\uc6a9\ud558\ub294 \uacbd\uc6b0\uac00 \ub9ce\uc774 \uc788\uc2b5\ub2c8\ub2e4.\\n- \ucd5c\uadfc\uc5d0\ub294 Implicit Representation Network \uc0c1\uc5d0\uc11c\ub3c4 Swish\uac00 \ub2e4\uc2dc\uae08 \uc8fc\ubaa9\uc744 \ubc1b\uace0 \uc788\uc2b5\ub2c8\ub2e4.\\n    - SIREN\uc5d0\uc11c \uc5b8\uae09\ud558\ub294 periodic function activation (Sine \ud568\uc218 \ub4f1) \ubcf4\ub2e4 Swish\uac00 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294 Task\uac00 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n### Sigmoid\\n\\n$$\\n\\\\sigma(x)=\\\\frac{1}{1+e^{-x}}\\n$$\\n\\n- \uc5ec\uae30\uc11c\ub294 Activation\uc73c\ub85c \uc2dc\uc0ac\ud558\uae30\ubcf4\ub2e4\ub294 \uc218\uc2dd \ud45c\ud604 \uc2dc\uc5d0 sigmoid\ub85c \ubb36\uc5b4 \ud45c\ud604\ud558\uae30 \uc704\ud574 \ud655\uc778\ud558\uace0 \ub118\uc5b4\uac00\uc57c \ud569\ub2c8\ub2e4.\\n- Swish\uac00 \uacb0\uad6d **input \uac12\uc5d0 sigmoid\ud55c \uac83\uacfc input \uac12\uc758 \uacf1\uc73c\ub85c \ud45c\ud604\ub41c\ub2e4**(\u03b2 \ub97c \uacf1\ud558\uae30\ub294 \ud558\uaca0\uc9c0\ub9cc)\ub294 \uac83\ub3c4 \ub2e4\uc2dc \ud55c\ubc88 \ub9ac\ub9c8\uc778\ub4dc\ud558\uace0 \ub118\uc5b4\uac11\uc2dc\ub2e4 \ud83d\ude0e\\n\\n### Maxout Family\\n\\n- ReLU\uc640 \uac19\uc740 Activation Function\uc758 \ucd9c\ubc1c\uc810\uc5d0 \ud574\ub2f9\ud558\ub294 \uac1c\ub150 \uc911 \ud558\ub098\uc785\ub2c8\ub2e4.\\n- Goodfellow\uc640 Bengio\uc758 \ub17c\ubb38[<sup>[2]</sup>](#r2) \uc73c\ub85c, Maximum\uc744 \uc120\ud0dd\ud558\ub294 \uac83\uc73c\ub85c\ub3c4 \uc784\uc758\uc758 Convex Function\uc5d0 \ub300\ud574 \ub450\ub8e8 \uadfc\uc0ac\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.\\n\\n## Main Idea\\n\\n### ACON(**Ac**tivationOrNot) Activation Function\\n\\n$$\\n\\\\operatorname{ACON-C}(x) := \\\\left(p_{1}-p_{2}\\\\right) x \\\\cdot \\\\sigma\\\\left(\\\\beta\\\\left(p_{1}-p_{2}\\\\right) x\\\\right)+p_{2} x\\n$$\\n\\n<img className={styles.figCenter} src={figAcon} alt=\\"figure4_acon\\" />\\n\\n*ACON Activation\uc744 \uc0ac\uc6a9\ud558\uc600\uc744 \ub54c, \ud2b9\uc815 Layer\uc758 Activation\uc774 Linear \ud558\uac8c pass\uc218\ub3c4, Non-linear Activation\uc73c\ub85c \ud65c\uc131\ub420 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4*\\n\\n\uc800\uc790\ub294 ACON(\ub354 \ub098\uc544\uac00\uc11c Meta-ACON)\uc774\ub77c\uace0 \ud558\ub294 Activation Function\uc744 \uc81c\uc548\ud569\ub2c8\ub2e4. ACON activation\uc740 trainable\ud55c activation\uc73c\ub85c Neuron\uc744 Activation\ud560 \uc9c0 \uc548 \ud560\uc9c0\ub97c \uac01 Layer\uc758 \ud2b9\uc131\uc5d0 \ub9de\uac8c \uacb0\uc815\ud569\ub2c8\ub2e4.\\n\\n\\n\\n### \uc5b4\ub5bb\uac8c \ud574\uc11c ACON \uc2dd\uc744 \ub3c4\ucd9c\ud560 \uc218 \uc788\uac8c \ub418\uc5c8\uc744\uae4c\uc694?\\n\\n\uba3c\uc800 Maximum Function $max(x1, ..., xn)$ \uc5d0 \ub300\ud574 smooth\ub41c \ubc84\uc804\uc744 \ubcf4\uc544\uc57c \ud569\ub2c8\ub2e4. Maximum\uc744 \uad6c\ud55c\ub2e4\ub294 \uac83\uc740 \uc77c\ubc18\uc801\uc73c\ub85c differentiable\ud558\uc9c0 \uc54a\uc9c0\ub9cc, \uc774\ub97c smooth\ud55c \ud568\uc218\ub294 differentiable\ud558\uac8c \ub429\ub2c8\ub2e4.\\n\\n\ubcf4\ud1b5 \uc544\ub798\uc758 \uc2dd\ucc98\ub7fc \ud45c\ud604\ud569\ub2c8\ub2e4.\\n\\n$$\\nS_{\\\\beta}\\\\left(x_{1}, \\\\ldots, x_{n}\\\\right)=\\\\frac{\\\\sum_{i=1}^{n} x_{i} e^{\\\\beta x_{i}}}{\\\\sum_{i=1}^{n} e^{\\\\beta x_{i}}}\\n$$\\n\\n\uc774 \ub54c, $\u03b2$ \ub294 switching factor\ub85c\uc11c\\n\\n- $\u03b2 \u2192 \u221e$\uc77c \ub54c, \uc8fc\uc5b4\uc9c4 \ud568\uc218\ub294 Maximum Function \uc758 \uc5ed\ud560\uc744 \ud558\uac8c \ub429\ub2c8\ub2e4.\\n- $\u03b2 \u2192 0$\uc77c \ub54c, \uc8fc\uc5b4\uc9c4 \ud568\uc218\ub294 \uc0b0\uc220\ud3c9\uade0(Arithmetic Mean, \uc6b0\ub9ac\uac00 \uc77c\ubc18\uc801\uc73c\ub85c \uc544\ub294 \ud3c9\uade0)\ucc98\ub7fc \uc791\ub3d9\ud569\ub2c8\ub2e4.\\n\\n\uc77c\ubc18\uc801\uc73c\ub85c Neural Network\uc5d0\uc11c \ub9ce\uc774 \uc0ac\uc6a9\ud558\ub294 Activation Function\ub4e4\uc740 \uc704\uc5d0\uc11c \uc5b8\uae09\ud55c Maxout\uc5d0 \uc900\ud558\ub294 \uac83\uc73c\ub85c \ud45c\ud604\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n$$\\nmax( \u03b7a(x), \u03b7b(x))\\n$$\\n\\n\uc608\ub97c \ub4e4\uc5b4, ReLU\ub294 $\u03b7a(x)=x$, $\u03b7b(x)=0$\uc778 \uac83\uc73c\ub85c \uc0dd\uac01\ud558\uba74, \uc774 \uc5ed\uc2dc Maxout Family\uc5d0 \uc18d\ud55c\ub2e4\uace0 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \\nLeaky ReLU, FReLU \ub4f1\ub3c4 \uc774\ub7ec\ud55c \ubc29\uc2dd\uc73c\ub85c \uc811\uadfc\ud574\ubcf4\uba74 \ubaa8\ub450 Maxout Family\uc5d0 \uc18d\ud558\uac8c \ub429\ub2c8\ub2e4.\\n\\n\ubcf8 \ub17c\ubb38\uc5d0\uc11c\uc758 \ubaa9\ud45c\ub294 Maximum Function\uacfc \uc704 Maxout Family\ub97c \ud568\uaed8 \uc0ac\uc6a9\ud558\uc5ec, Maxout Family \uac01\uac01\uc5d0 \uc0c1\uc751\ud558\ub294 activation function\ub4e4\uc744 smooth\ud55c \ud568\uc218\ub85c \uadfc\uc0ac\ud574\ubcf4\ub294 \uac83\uc785\ub2c8\ub2e4. \uc704\uc5d0\uc11c Smooth\ub41c Maximum Function\uc744 \uc791\uc131\ud560 \ub54c, \uc785\ub825 \uac12\uc758 \uac1c\uc218\ub97c 2\uac1c\ub85c\ub9cc \ud55c\uc815\ud574\uc11c \uc2dd\uc744 \uc804\uac1c\ud558\uba74 \ub531\uc774\uaca0\ub124\uc694!\\n\\n$$\\n\\\\begin{array}{l}S_{\\\\beta}\\\\left(\\\\eta_{a}(x), \\\\eta_{b}(x)\\\\right) \\\\\\\\=\\\\eta_{a}(x) \\\\cdot \\\\frac{e^{\\\\beta \\\\eta_{a}(x)}}{e^{\\\\beta \\\\eta_{a}(x)}+e^{\\\\beta \\\\eta_{b}(x)}}+\\\\eta_{b}(x) \\\\cdot \\\\frac{e^{\\\\beta \\\\eta_{b}(x)}}{e^{\\\\beta \\\\eta_{a}(x)}+e^{\\\\beta \\\\eta_{b}(x)}} \\\\\\\\=\\\\eta_{a}(x) \\\\cdot \\\\frac{1}{1+e^{-\\\\beta\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right)}}+\\\\eta_{b}(x) \\\\cdot \\\\frac{1}{1+e^{-\\\\beta\\\\left(\\\\eta_{b}(x)-\\\\eta_{a}(x)\\\\right)}} \\\\\\\\=\\\\eta_{a}(x) \\\\cdot \\\\sigma\\\\left[\\\\beta\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right)\\\\right]+\\\\eta_{b}(x) \\\\cdot \\\\sigma\\\\left[\\\\beta\\\\left(\\\\eta_{b}(x)-\\\\eta_{a}(x)\\\\right)\\\\right] \\\\\\\\=\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right) \\\\cdot \\\\sigma\\\\left[\\\\beta\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right)\\\\right]+\\\\eta_{b}(x)\\\\end{array}\\n$$\\n\\n\uc989, Smooth\ub41c Maximum Function\uc5d0 \ub300\uc785\ud574\uc11c \uc804\uac1c\ud574\ubcf4\uba74\\n\\n$$\\n\\\\begin{array}{l}S_{\\\\beta}\\\\left(\\\\eta_{a}(x), \\\\eta_{b}(x)\\\\right) =\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right) \\\\cdot \\\\sigma\\\\left[\\\\beta\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right)\\\\right]+\\\\eta_{b}(x)\\\\end{array}\\n$$\\n\\n\uc774 \ub420 \uac83\uc785\ub2c8\ub2e4!\\n\\n### ACON \uc548\uc5d0 Swish \uc788\ub2e4 \ud83d\ude09\\n\\n\uc790, \uadf8\ub7fc \uc544\uae4c \uc5b8\uae09\ud55c Maxout Family\uc5d0 \uc900\ud558\uc5ec \uc5ec\ub7ec Activation\uc744 \ud45c\ud604\ud560 \uc218 \uc788\uc5c8\ub2e4\uba74, \uac01\uac01\uc744 Smooth\ub41c Maximum Function\uc5d0 \ud574\ub2f9\ud558\ub3c4\ub85d \uc804\uac1c\ub97c \ud574\ubcfc\uae4c\uc694?\\n\\n<img className={styles.figCenter} src={figFamily} alt=\\"figure5_maxout_family_acon_family\\" />\\n\\n\\nReLU\uc758 smooth\ub418\ub294 \ubc84\uc804\uc774 Swish\ub77c\ub294 \uac74 \uc9c1\uad00\uc73c\ub85c\ub3c4 \ub9ce\uc774\ub4e4 \uc774\ud574\ud558\uace0 \uc788\uc5c8\ub294\ub370\uc694. \uc774 \uc2dd\uc5d0\uc11c \ubcf4\ub4ef\uc774 Smooth\ub41c Maximum Function\uc5d0 \ub300\uc785\ud574\uc11c \uc804\uac1c\ud574\ubcf4\uba74, \ubc14\ub85c Swish \uc2dd\uc774 \ub098\uc624\uac8c \ub429\ub2c8\ub2e4. \uc800\uc790\ub294 \uc774\ub97c \ud1b5\ud574 Swish\uac00 ReLU\uc758 Smooth Approximation\uc784\uc744 \ud45c\ud604\ud560 \uc218 \uc788\uac8c \ub41c\ub2e4\uace0 \ub9d0\ud569\ub2c8\ub2e4.\\n\\n\ub610\ud55c, Leaky ReLU\uc758 \uc0c1\uc704 \ud638\ud658\uc774\uae30\ub3c4 \ud55c PReLU(Parametric ReLU, \uc74c\uc218 \ubd80\ubd84\uc758 \uae30\uc6b8\uae30 \uac12\uc774 learnable\ud568)\ub3c4 \uc0b4\ud3b4\ubcf4\uba74, \uc5ed\uc2dc Smooth\ub418\ub294 \ud568\uc218\ub85c \ub300\uc751\ud558\ub294 \uac83\uc744 \ucc3e\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. (\uc544 \uc774 \ub54c PReLU\uc5d0 \ub300\uc751\ud558\ub824\uba74, p < 1 \uc778 \uac78\ub85c \ud55c\uc815\ud574\uc11c \uc0dd\uac01\ud574\ubd10\uc694 \uc6b0\ub9ac \ud83d\ude42)\\n\\n\uadf8\ub9ac\uace0 \ub9c8\uc9c0\ub9c9\uc73c\ub85c \uac01 \uc120\ud615 \ud568\uc218\uc758 \uac00\uc911\uce58(Cartesian \uc88c\ud45c\uacc4 \uc0c1\uc740 \uae30\uc6b8\uae30\uaca0\uc8e0?)\uac00 p1, p2\ub85c \ud45c\ud604\ud558\uba74 \uac00\uc7a5 \uc77c\ubc18\ud654\ub41c \ud45c\ud604\uc77c\ud150\ub370\uc694 (p1 \u2260 p2). \uc5ec\uae30\uc5d0 \uac01\uac01 Maxout Family, ACON Family\ub97c \ub300\uc751\ud574\ubcf4\uba74 \uc77c\ubc18\ud654\ub41c \uc2dd\uc774 \ub098\uc635\ub2c8\ub2e4. \uc704\uc5d0\uc11c \uc5b8\uae09\ud55c\\n\\n$$\\n\\\\operatorname{ACON-C}(x):=\\\\left(p_{1}-p_{2}\\\\right) x \\\\cdot \\\\sigma\\\\left(\\\\beta\\\\left(p_{1}-p_{2}\\\\right) x\\\\right)+p_{2} x\\n$$\\n\\n\uc774 \uc774\ub807\uac8c \uc720\ub3c4\ub418\uac8c \ub418\ub294 \uac83\uc774\uc8e0!\\n\\n\uc0ac\uc2e4 Maxout Family\uc5d0\uc11c \ube44\uad50\ud558\uac8c \ub418\ub294 \ub450 \ud568\uc218\ub294 \uc704\uc5d0\uc11c\ucc98\ub7fc \ub2e8\uc21c\ud558\uc9c0 \uc54a\uc744 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. \uac01\uac01\uc774 \ubcf5\uc7a1\ud574\uc9c8\uc218\ub85d \ub354 \ub9ce\uc740 \ud568\uc218\ub4e4\uc744 \ud45c\ud604\ud560 \uc218 \uc788\uac8c \ub418\uc8e0. \ub2e4\ub9cc, \uc800\uc790\ub294 \uc774 Maxout Family\ub97c ACON Family\ub85c \ubc14\uafe8\uc744 \ub54c(\uc989, Smooth Maximum Function\uc73c\ub85c \uadfc\uc0ac\ud588\uc744 \ub54c)\uc758 \ud6a8\uacfc\ub97c \ubcf4\ub294 \ub370\uc5d0 \uc5f0\uad6c\ub97c \uc9d1\uc911\ud588\ub2e4\uace0 \ud574\uc694. \ud5a5\ud6c4 \uc5f0\uad6c\uc5d0\uc11c \ub354 \uc804\uccb4\uc801\uc778 Scope\uc5d0\uc11c\uc758 \ube44\uad50\uac00 \uc788\uae30\ub97c \uae30\ub300\ud574\ubd05\ub2c8\ub2e4!\\n\\n### ACON\uc758 \ud2b9\uc131\\n\\nACON\uc5d0 \ud2b9\uc815 \uac12\uc744 \ub300\uc785\ud574\uc11c \ud55c\ubc88 \uc0b4\ud3b4\ubcfc\uae4c\uc694?\\n\\n<img className={styles.figCenter} src={figExample} alt=\\"figure6_acon_example\\" />\\n\\np1=1.2, p2=-0.8\uc77c \ub54c ACON-C\uc5d0 \ub300\uc751\ud558\ub294 \uc2dd\uc744 \uc5ec\ub7ec \u03b2\uac12\uc5d0 \ub300\ud574 \ud45c\ud604\ud55c graph\uc785\ub2c8\ub2e4.\\n\\n- \u03b2\uac00 \ud074 \ub54c\ub294, maximum function\ucc98\ub7fc \ubc18\uc751\ud558\uc5ec \ube44\uc120\ud615\uc801\uc778 \ud2b9\uc131\uc744 \uac16\uac8c \ub418\uace0\uc694.\\n- \u03b2\uac00 0\uc5d0 \uac00\uae4c\uc6b8 \ub54c\ub294 mean function\uc5d0 \uadfc\uc0ac\ub418\uc5b4 \uc120\ud615\uc801\uc778 \ud2b9\uc131\uc744 \uac16\ub124\uc694.\\n\\n<img className={styles.figCenter} src={figProperty} alt=\\"figure7_acon_property\\" />\\n\\nACON Activation\uacfc \uc774\uc5d0 \ub300\ud55c \ub3c4\ud568\uc218(derivative)\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub9bc\uc785\ub2c8\ub2e4.\\n\\n- \uc67c\ucabd: \u03b2\uac00 fixed \ub418\uc5b4 \uc788\uc744 \ub54c, p1, p2 \uacc4\uc218\uc5d0 \ub530\ub77c \uc5b4\ub5bb\uac8c Activation function\uc774 \ub2ec\ub77c\uc9c0\ub294 \uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\\n- \uac00\uc6b4\ub370: \u03b2 \uac12\uc774 \ub2ec\ub77c\uc9d0\uc5d0 \ub530\ub77c ACON\uc758 \ub3c4\ud568\uc218\uac00 \ubcc0\ud654\ud558\uac8c \ub418\uace0 \uc774\ub97c \ud1b5\ud574 \u03b2\uc758 \uc5ed\ud560\uc744 \uc9d0\uc791\ud574\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n- \uc624\ub978\ucabd: \u03b2\uac00 fixed \ub418\uc5b4 \uc788\uc744 \ub54c, p1, p2 \uacc4\uc218\uc5d0 \ub530\ub77c ACON\uc758 \ub3c4\ud568\uc218\uac00 \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294 \uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\\n\\nACON\uc758 \ub3c4\ud568\uc218\ub97c \ubcf4\uba74\uc11c \uc544\ub798\uc640 \uac19\uc740 \uc0ac\uc2e4\uc744 \uc54c \uc218 \uc788\uc5b4\uc694.\\n\\n- p1, p2\ub294 \uac01\uac01 Upper/Lower Bound\uc5d0 \ud574\ub2f9\ud558\ub294 \uac12\uc744 \uacb0\uc815\ud558\uac8c \ub429\ub2c8\ub2e4.\\n- \u03b2 \uac12\uc740 \ub3c4\ud568\uc218 \uc0c1\uc5d0\uc11c p1, p2\uc5d0 \uc758\ud574 \uacb0\uc815\ub41c Upper/Lower Bound\uc5d0 \uc5bc\ub9c8\ub098 \ube60\ub974\uac8c \uadfc\uc0ac\ub418\ub294 \uc9c0\ub97c \uacb0\uc815\ud558\uac8c \ub429\ub2c8\ub2e4.\\n\\nSwish\uc5d0\uc11c\ub294 Hyperparameter \u03b2\ub9cc\uc774 Upper/Lower Bound\uc5d0 \uc5bc\ub9c8\ub098 \ube68\ub9ac \uadfc\uc0ac\ub418\ub294 \uc9c0\ub97c \uacb0\uc815\ud558\uac8c \ub418\ub294\ub370\uc694. ACON\uc5d0\uc11c\ub294 p1, p2\uac00 \uc774 Bound \uac12\uc744 \uacb0\uc815\ud558\uac8c \ub418\uace0, \uc774 \uc5ed\uc2dc learnable\ud574\uc9c8 \uc218 \uc788\ub2e4\ub294 \ud2b9\uc131\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub807\uac8c boundary\uac00 learnable\ud558\ub2e4\ub294 \uac83\uc740 optimization\uc744 \uc27d\uac8c \ud558\ub294 \ub370\uc5d0 \ud544\uc218\uc801\uc778 \ud2b9\uc131\uc774\uace0, \uc800\uc790\ub294 \uc774 \uc7a5\uc810\uc744 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ud1b5\ud574 \ubcf4\uc5ec\uc8fc\uace0 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n### \ud559\uc2b5\uc5d0 \ubaa8\ub450 \ub9e1\uaca8\ubc84\ub9ac\uc790! Meta-ACON\\n\\nMeta-ACON\uc740 \u03b2 \uc790\uccb4\ub97c Learnable\ud55c parameter\ub85c \ub194\ub450\ub294 \uac83\uc5d0\uc11c \ub354 \ub098\uc544\uac00, Layer\uc5d0 \uc785\ub825\ub418\ub294 feature map\uc73c\ub85c\ubd80\ud130 FC Layers\ub97c \uac70\uccd0 estimation \ub418\ub3c4\ub85d \ub9cc\ub4e0 \uac83\uc785\ub2c8\ub2e4.\\n\\n<img className={styles.figCenter} src={figDistribution} alt=\\"figure8_meta_acon_distribution\\" />\\n\\nACON\uacfc meta-ACON\uc744 \ube44\uad50\ud55c \ub3c4\uc2dd\uc785\ub2c8\ub2e4. ResNet50\uc758 \ub9c8\uc9c0\ub9c9 BottleNeck Layer\uc5d0\uc11c\uc758 activation\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \uc5ec\uae30\uc5d0\uc11c 7\uac1c\uc758 sample\uc744 \uc784\uc758\ub85c \ucd94\ucd9c\ud574\ubd24\uc2b5\ub2c8\ub2e4.\\n\\n- ACON\uc5d0\uc11c \ucd94\ucd9c\ud560 \uacbd\uc6b0, \ud30c\ub780 \ud788\uc2a4\ud1a0\uadf8\ub7a8\uc5d0 \ud574\ub2f9\ud558\ub294\ub370\uc694. 7\uac1c\uc758 sample\uc774 \ub3d9\uc77c\ud55c \u03b2 distribution\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.\\n- Meta-ACON\uc5d0\uc11c\ub294 7\uac1c\uc758 sample\uc774 \uc11c\ub85c \ub2e4\ub978 \u03b2 distribution\uc744 \ubcf4\uc5ec\uc8fc\uac8c \ub429\ub2c8\ub2e4. \uc5ec\uae30\uc11c \u03b2 \uac12\uc774 \uc791\uc744\uc218\ub85d, \uc120\ud615\uc801\uc73c\ub85c(linear) \ubc18\uc751\ud558\ub294 \uac83\uc774\uace0, \u03b2 \uac12\uc774 \ud074 \uc218\ub85d \ube44\uc120\ud615\uc801(non-linear)\uc73c\ub85c \ubc18\uc751\ud558\uace0 \uc788\ub294 \uac83\uc785\ub2c8\ub2e4.\\n\\nCode Snippet\uc73c\ub85c \ubcf4\uba74 \uc544\ub798\uc640 \uac19\uc2b5\ub2c8\ub2e4. \ubcf8 Snippet\uc740 \uc800\uc790\uc758 [official github](https://github.com/nmaac/acon)\uc5d0\uc11c \ubc1c\ucdcc\ud588\uc73c\uba70, \ud574\ub2f9 Repository\uc5d0\uc11c \uc790\uc138\ud55c \ucf54\ub4dc\ub97c \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n<script src=\\"https://gist.github.com/deepkyu/1616637a06e1b00534a7557c35ad2209.js\\"><\/script>\\n<script src=\\"https://gist.github.com/deepkyu/77b2e5acd98969fdb21ea22198954ad5.js\\"><\/script>\\n\\n### \uacb0\uacfc\\n\\n| ImageNet Classification Result       | Accuracy Improvements       |\\n| --------------------------- | --------------------------- |\\n| ![figure9_result1.png](./image/figure9_result1.png) | ![figure10_result2.png](./image/figure10_result2.png) |\\n\\nImageNet Classification\uc5d0 \ub300\ud55c ShuffleNetV2 \uae30\uc900 \uacb0\uacfc\ub97c \uc0b4\ud3b4\ubcf4\uba74, \ud559\uc2b5 \uc18d\ub3c4\ub3c4 \ube60\ub97c \ubfd0\ub354\ub7ec, Meta-ACON\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c Error rate\uac00 \ub0ae\uc544\uc9c0\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub610\ud55c, \uc804\ubc18\uc801\uc73c\ub85c \ubaa8\ub378 \uc0ac\uc774\uc988\uac00 \ucee4\uc9c8 \uc218\ub85d, Meta-ACON\uc744 \uc0ac\uc6a9\ud560 \uc218\ub85d Accuracy \ud5a5\uc0c1\uc774 \ud07d\ub2c8\ub2e4. (Swish \ub300\uccb4, SENet Novelty \ucd94\uac00 \ub4f1 \ub300\ube44)\\n\\n<img className={clsx(styles.figCenter, styles.medium)} src={figResultFour} alt=\\"figure12_result4\\" />\\n<img className={clsx(styles.figCenter, styles.medium)} src={figResultFive} alt=\\"figure13_result5\\" />\\n\\n\uc774\ub807\uac8c Meta-ACON\uc740 \ub2e4\ub978 activation \ub300\ube44 ImageNet Classification\uc5d0\uc11c \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\uace0 \uc788\uc2b5\ub2c8\ub2e4. \ub610\ud55c, \uc81c\ud55c\uc801\uc774\uae30\ub294 \ud558\ub098, \ud2b9\uc815 backbone\uc5d0 \ub300\ud574\uc11c Object Detection \ubc0f Semantic Segmentation\uc5d0 \uc788\uc5b4\uc11c\ub3c4 \ub2e4\ub978 activation function\uc744 \uc0ac\uc6a9\ud560 \ub54c\ubcf4\ub2e4 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\\n\\n### \ub9c8\ubb34\ub9ac\\n\\n\uc774\ub807\uac8c \uc624\ub298\uc740 ReLU\uc640 Swish \uac04\uc758 \uad00\uacc4\ub97c \ud1b5\ud574 \uc0c8\ub85c\uc6b4 Activation Function\ub4e4\uc774 \ud3ec\uc9c4\ub418\uc5b4 \uc788\uc744\ub9cc\ud55c \uc77c\ubc18\ud654\ub41c \uc2dd\uc744 \ucc3e\uace0(ACON Family), \uc774\ub97c \uae30\ubc18\uc73c\ub85c Trainable\ud55c Activation Function\uc744 \uc0c8\ub85c \ub9cc\ub098\ubcfc \uc218 \uc788\uc5c8\uc2b5\ub2c8\ub2e4.  \\n\uc0ac\uc2e4 \uc774\ub807\uac8c \ud6c8\ub828 \uac00\ub2a5\ud55c \ud30c\ub77c\ubbf8\ud130\ub97c \uac00\uc9c4 Activation Function\uc774 ACON\ub9cc \ucc98\uc74c\uc778 \uac83\uc740 \uc544\ub2d9\ub2c8\ub2e4. \ub610\ud55c, \uc5ec\ub7ec Sub-task\uc5d0 \ub300\ud574 \ubc94\uc6a9\uc801\uc73c\ub85c \uc0ac\uc6a9\ub420 \uc218 \uc788\ub294 Activation Function\uc77c\uc9c0\ub294 \ubbf8\uc9c0\uc218\uc774\uae30\ub3c4 \ud558\uace0\uc694. \ud2b9\ud788 \ubaa8\ub378 \uacbd\ub7c9\ud654 \ub4f1 \uc5b4\ub290 \ud55c\ud3b8\uc5d0\uc11c\ub294 Non-linear Activation Function\ub9c8\uc800 Bottleneck\uc73c\ub85c \uc9da\uace0 \ub118\uc5b4\uac00\ub294 \uc2e4\uc815\uc774\uae30\uc5d0[<sup>[3]</sup>](#r3), \ubaa8\ub4e0 \ubaa9\uc801\uc744 \ub9cc\uc871\uc2dc\ud0ac\ub9cc\ud55c \uc0c8\ub85c\uc6b4 \ud65c\uc131 \ud568\uc218\ub97c \ucc3e\uc740 \uc5f0\uad6c\ub294 \uc544\ub2d9\ub2c8\ub2e4. \ub2e4\ub9cc, \uc2dd\uc5d0 \ub300\ud55c \uac04\ub2e8\ud55c \uc815\ub9ac\ub85c ReLU\uc640 Swish \uac04\uc758 \uad00\uacc4\ub97c \ubcf4\uc784\uacfc \ub3d9\uc2dc\uc5d0, \uc0c8\ub85c\uc6b4 Activation Family\ub97c \uc81c\uc2dc\ud588\ub2e4\ub294 \ub370\uc5d0 \uc758\uc758\uac00 \uc788\ub294 \ub17c\ubb38\uc774\uc5c8\uc2b5\ub2c8\ub2e4.\\n\\nCVPR 2021\uc5d0\uc11c \uc774\ub7ec\ud55c \ub17c\ubb38\ub3c4 \ubc1c\ud45c\ub41c\ub2e4\ub294 \uac83\uc744 \ud568\uaed8 \uacf5\uc720\ud558\uace0 \uc2f6\uc5b4 \uac04\ub7b5\ud558\uac8c\ub098\ub9c8 \ub9ac\ubdf0\ub97c \uc9c4\ud589\ud574\ubd24\uc2b5\ub2c8\ub2e4 :+1:\\n\\n\\n### References (+ \ud568\uaed8 \uc77d\uc73c\uba74 \uc88b\uc740 \ub17c\ubb38\ub4e4)\\n\\n<a name=\\"r1\\"></a>\\n\\n1. Ramachandran, Prajit, Barret Zoph, and Quoc V. Le. \\"Searching for activation functions.\\" arXiv preprint arXiv:1710.05941 (2017). [[paper]](https://arxiv.org/abs/1710.05941) \\n\\n<a name=\\"r2\\"></a>\\n\\n2. Goodfellow, Ian, et al. \\"Maxout networks.\\" International conference on machine learning. PMLR, 2013. [[paper]](http://proceedings.mlr.press/v28/goodfellow13.html)\\n\\n<a name=\\"r3\\"></a>\\n\\n3. Han Cai, Chuang Gan, Ligeng Zhu, and Song Han. \\"TinyTL: Reduce Memory, Not Parameters for Efficient On-Device Learning\\n.\\" Part of Advances in Neural Information Processing Systems 33 (NeurIPS 2020) [[paper]](https://proceedings.neurips.cc//paper_files/paper/2020/hash/81f7acabd411274fcf65ce2070ed568a-Abstract.html)\\n\\n\\n\\n### TL;DR\\n\\n- Activation function\ub4e4\uc5d0 \ub300\ud574 \uae30\uc874 Maxout family\uc5d0 \ud574\ub2f9\ud558\ub294 \uc77c\ubc18\ud654\ub97c \ub118\uc5b4 **ACON Family**\ub77c\ub294 \uac1c\ub150\uc73c\ub85c \ud655\uc7a5\ud558\uc5ec \uc77c\ubc18\ud654\ub97c \ud569\ub2c8\ub2e4.\\n- \uc774\ub97c \ud1b5\ud574 ACON Family\uc5d0\uc11c \uac01 activation\uc744 \uacb0\uc815 \uc9d3\ub294 parameter \uc790\uccb4\ub97c learnable\ud558\uac8c \ud558\uc5ec **acon** \uc774\ub77c\ub294 activation\uc744 \uc0c8\ub86d\uac8c \uc81c\uc2dc\ud569\ub2c8\ub2e4.\\n- \uae30\uc874 Swish \ub294 NAS\ub85c \ucc3e\uc740 activation\uc73c\ub85c\uc11c, \ub354 \uc88b\ub2e4\ub294 \uac83\ub9cc \uc54c \ubfd0, \uc65c \uc88b\uc740\uc9c0\ub97c \ubab0\ub790\ub294\ub370, **ACON Family**\uc5d0 \ub300\uc751\ud558\uc5ec \ubd24\uc744 \ub54c, \uc774\ub97c \uc5b4\ub290\uc815\ub3c4 \uc124\uba85\ud560 \uc218 \uc788\uac8c \ub429\ub2c8\ub2e4."}]}')}}]);