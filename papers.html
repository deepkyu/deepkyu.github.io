<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.17">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Hyoung-Kyu Song RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Hyoung-Kyu Song Atom Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-223362952-2","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
<link rel="alternate" type="application/rss+xml" href="/story/rss.xml" title="Hyoung-Kyu Song RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/story/atom.xml" title="Hyoung-Kyu Song Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/papers/rss.xml" title="Hyoung-Kyu Song RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/papers/atom.xml" title="Hyoung-Kyu Song Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous">
<script src="js/scroll.js"></script><title data-rh="true">Blog | Hyoung-Kyu Song</title><meta data-rh="true" property="og:title" content="Blog | Hyoung-Kyu Song"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" name="description" content="Blog"><meta data-rh="true" property="og:description" content="Blog"><meta data-rh="true" property="og:url" content="https://deepkyu.github.io//papers"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="blog_posts_list"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_posts_list"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://deepkyu.github.io//papers"><link data-rh="true" rel="alternate" href="https://deepkyu.github.io//papers" hreflang="en"><link data-rh="true" rel="alternate" href="https://deepkyu.github.io//papers" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.612d8e13.css">
<link rel="preload" href="/assets/js/runtime~main.bfc8b893.js" as="script">
<link rel="preload" href="/assets/js/main.f586578e.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Deepkyu" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/logo.svg" alt="Deepkyu" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title"></b></a><a class="navbar__item navbar__link" href="/blog">Blog</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/papers">Paper Reviews</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/cv">CV</a><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://www.linkedin.com/in/deepkyu" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_S7eR toggle_TdHA toggleDisabled_f9M3"><div class="toggleButton_rCf9" role="button" tabindex="-1"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_v35p"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_nQuB"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></div><input type="checkbox" class="toggleScreenReader_g2nN" aria-label="Switch between dark and light mode (currently light mode)"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-list-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_a9qW thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_uKok margin-bottom--md">All Posts</div><ul class="sidebarItemList_Kvuv"><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/papers/acon">Activate or Not: Learning Customized Activation</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/papers/anycost">Anycost GANs for Interactive Image Synthesis and Editing</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/papers/diffaugment">Differentiable Augmentation for Data-Efficient GAN Training</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/papers/freezed">FreezeD: a Simple Baseline for Fine-tuning GANs</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/papers/acon">Activate or Not: Learning Customized Activation</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2021-07-19T00:00:00.000Z" itemprop="datePublished">July 19, 2021</time> · <!-- -->15 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/deepkyu.png" alt="Hyoung-Kyu Song"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Hyoung-Kyu Song</span></a></div><small class="avatar__subtitle" itemprop="description">AI Researcher (Vision)</small></div></div></div></div></header><meta itemprop="image" content="https://deepkyu.github.io//img/default.png"><div class="markdown" itemprop="articleBody"><p><a href="https://arxiv.org/abs/2009.04759" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-2009.04759-brightgreen.svg?style=flat-square" alt="arXiv"></a>
<a href="https://github.com/nmaac/acon" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?message=Official%20Repo&amp;logo=Github&amp;labelColor=grey&amp;color=blue&amp;logoColor=white&amp;label=%20&amp;style=flat-square" alt="githubio"></a></p><blockquote><p>Ma, Ningning, et al. &quot;Activate or Not: Learning Customized Activation.&quot;<br>
<!-- -->Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.</p></blockquote><br><div class="admonition admonition-info alert alert--info"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</h5></div><div class="admonition-content"><p>업무 중에 진행된 논문 리뷰로 <a href="https://mindslab-ai.github.io" target="_blank" rel="noopener noreferrer">마인즈랩 Brain팀 Tech Blog</a>에서도 확인하실 수 있습니다.</p></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="contribution">Contribution<a class="hash-link" href="#contribution" title="Direct link to heading">​</a></h2><ul><li>Activation function들에 대해 기존 Maxout family에 해당하는 일반화를 넘어 <strong>ACON Family</strong>라는 개념으로 확장하여 일반화를 합니다.</li><li>이를 통해 ACON Family에서 각 activation을 결정 짓는 parameter 자체를 learnable하게 하여 <strong>acon</strong> 이라는 activation을 새롭게 제시합니다.</li><li>기존 Swish 는 NAS로 찾은 activation으로서, 더 좋다는 것만 알 뿐, 왜 좋은지를 몰랐는데, <strong>ACON Family</strong>에 대응하여 봤을 때, 이를 어느정도 설명할 수 있게 됩니다.</li></ul></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/papers/tags/paper-review">paper-review</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/papers/tags/activation">activation</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Activate or Not: Learning Customized Activation" href="/papers/acon"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/papers/anycost">Anycost GANs for Interactive Image Synthesis and Editing</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2021-05-14T00:00:00.000Z" itemprop="datePublished">May 14, 2021</time> · <!-- -->5 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/deepkyu.png" alt="Hyoung-Kyu Song"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Hyoung-Kyu Song</span></a></div><small class="avatar__subtitle" itemprop="description">AI Researcher (Vision)</small></div></div></div></div></header><meta itemprop="image" content="https://deepkyu.github.io//img/default.png"><div class="markdown" itemprop="articleBody"><p><a href="https://github.com/mit-han-lab/anycost-gan" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?message=Official%20Repo&amp;logo=Github&amp;labelColor=grey&amp;color=blue&amp;logoColor=white&amp;label=%20&amp;style=flat-square" alt="githubio"></a></p><blockquote><p>Lin, Ji, et al. &quot;Anycost gans for interactive image synthesis and editing.&quot;
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.</p></blockquote><p>Song Han (Network Compression 최강) + Jun-Yan Zhu (GAN 최강)</p><br><h2 class="anchor anchorWithStickyNavbar_mojV" id="contribution">Contribution<a class="hash-link" href="#contribution" title="Direct link to heading">​</a></h2><img class="figCenter__7gH" src="/assets/images/fig1_model-general-62740d0c269966dfdc9a85ef63ebe71e.png" alt="model-general"><ul><li>Intermediate Layer도 Generation의 결과물이 될 수 있다는 부분을 시사한 연구다.</li><li>Low Resolution Preview를 추출하는 데에 별도의 네트워크를 구성하거나, 속도 측면에서 손해보는 것 없이 구현을 했다는 점에서 앞으로의 쓰임새가 기대되는 논문이다.</li><li>Depth Search를 하는 방식으로 일종의 네트워크 경량화를 해낸다는 아이디어는 기존에도 많이 있었는데, 이를 Image Generation에 적용한 몇 안 되는 논문일 것이고 G-conditioned Dsicriminator를 통해 Discriminator를 상황에 맞게 학습시키는 방법은 앞으로도 많이 차용할 수 있다.</li></ul></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/papers/tags/paper-review">paper-review</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/papers/tags/gan">gan</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/papers/tags/compression">compression</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Anycost GANs for Interactive Image Synthesis and Editing" href="/papers/anycost"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/papers/diffaugment">Differentiable Augmentation for Data-Efficient GAN Training</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2021-05-03T00:00:00.000Z" itemprop="datePublished">May 3, 2021</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/deepkyu.png" alt="Hyoung-Kyu Song"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Hyoung-Kyu Song</span></a></div><small class="avatar__subtitle" itemprop="description">AI Researcher (Vision)</small></div></div></div></div></header><meta itemprop="image" content="https://deepkyu.github.io//img/default.png"><div class="markdown" itemprop="articleBody"><p><a href="https://github.com/mit-han-lab/data-efficient-gans" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?message=Official%20Repo&amp;logo=Github&amp;labelColor=grey&amp;color=blue&amp;logoColor=white&amp;label=%20&amp;style=flat-square" alt="githubio"></a></p><blockquote><p>Zhao, Shengyu, et al. &quot;Differentiable augmentation for data-efficient gan training.&quot;<br>
<!-- -->Advances in Neural Information Processing Systems 33 (2020): 7559-7570.</p></blockquote><p>참고로 Song Han 연구실은 Neural Network Compression 분야에 있어 Top을 달리고 있는 연구실이다. 후에 소개할 AnycostGAN에서도 DiffAugment가 언급이 된다.</p><p>Han Lab은 기존에는 방법론에 있어 Network Pruning, KD(Knowledge Distillation) 등에 집중을 했고, TinyTL 등 Activation에 대한 경량화도 연구를 진행했다. 다만, 대부분 Task가 Image Recognition에 국한되어 있었다. Song Han은 CVPR2020에서 GAN Compression이라는 논문을 통해 Image Generation에 대한 Compression 논문을 시작으로, GAN 관련 연구를 지속해서 이어오고 있다.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/papers/tags/paper-review">paper-review</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/papers/tags/gan">gan</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Differentiable Augmentation for Data-Efficient GAN Training" href="/papers/diffaugment"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/papers/freezed">FreezeD: a Simple Baseline for Fine-tuning GANs</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2020-09-24T00:00:00.000Z" itemprop="datePublished">September 24, 2020</time> · <!-- -->8 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/deepkyu.png" alt="Hyoung-Kyu Song"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Hyoung-Kyu Song</span></a></div><small class="avatar__subtitle" itemprop="description">AI Researcher (Vision)</small></div></div></div></div></header><meta itemprop="image" content="https://deepkyu.github.io//img/default.png"><div class="markdown" itemprop="articleBody"><p><a href="https://github.com/sangwoomo/FreezeD" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?message=Official%20Repo&amp;logo=Github&amp;labelColor=grey&amp;color=blue&amp;logoColor=white&amp;label=%20&amp;style=flat-square" alt="githubio"></a></p><blockquote><p>Mo, Sangwoo, et al. &quot;Freeze the discriminator: a simple baseline for fine-tuning gans.&quot;<br>
<!-- -->CVPR AI for Content Creation Workshop (2020).</p></blockquote><h2 class="anchor anchorWithStickyNavbar_mojV" id="contribution">Contribution<a class="hash-link" href="#contribution" title="Direct link to heading">​</a></h2><p>GAN을 fine-tuning하는 데에 있어, discriminator의 lower layer들(classifier 말고 visul repr. (=visual feature) extractor)에 대해 freeze하고 G/D에 대해 fine-tuning을 진행하면, limited data로 효과적인 transfer learning을 할 수 있다.</p><p>즉, image classification 등 recognition(또는 understanding)에서 사용하는 fine-tuning 방식 (visual representation은 freeze, classifier만 use_gradient)이 GAN 모델에서도 유용하게 사용될 수 있다.</p><img class="figCenter__7gH" src="/assets/images/result_graph-131a4e1493d0c89f7b52e6d88ab11441.png" alt="result_graph"></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/papers/tags/paper-review">paper-review</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/papers/tags/gan">gan</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about FreezeD: a Simple Baseline for Fine-tuning GANs" href="/papers/freezed"><b>Read More</b></a></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Contents</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a class="footer__link-item" href="/papers">Reviews</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/story">Story</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://www.linkedin.com/in/deepkyu" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2022 Deepkyu. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.bfc8b893.js"></script>
<script src="/assets/js/main.f586578e.js"></script>
</body>
</html>