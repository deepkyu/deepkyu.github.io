---
slug: anycost
title: "Anycost GANs for Interactive Image Synthesis and Editing"
description: 하나의 GAN Training으로 여러 해상도의 이미지를 생성할 수 있게 한 연구를 소개합니다.
image: img/default.png
authors: [hkyu]
tags: [paper-review, gan, compression]
---

import clsx from 'clsx';
import styles from '../blog.module.css';

import figGeneral from './image/fig1_model-general.png';
import figArchi from './image/fig2_architecture.png';
import figTable from './image/fig3_table1.png';
import figAdaptiveCh from './image/fig4_adaptive_channel_training.png';
import figResultGraph from './image/fig5_result_graph.png';
import figChannelDiff from './image/fig6_channel_diff_result.png';
import figLsunResult from './image/fig7_LSUN_result.png';
import figMultiRes from './image/fig8_result_multiresolution.png';
import figLatentSpace from './image/fig9_latent_space_result.png';

[![githubio](https://img.shields.io/static/v1?message=Official%20Repo&logo=Github&labelColor=grey&color=blue&logoColor=white&label=%20&style=flat-square)](https://github.com/mit-han-lab/anycost-gan)

> Lin, Ji, et al. "Anycost gans for interactive image synthesis and editing."
> Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.

Song Han (Network Compression 최강) + Jun-Yan Zhu (GAN 최강)

<br/>


## Contribution

<img className={styles.figCenter} src={figGeneral} alt="model-general" />

- Intermediate Layer도 Generation의 결과물이 될 수 있다는 부분을 시사한 연구다.
- Low Resolution Preview를 추출하는 데에 별도의 네트워크를 구성하거나, 속도 측면에서 손해보는 것 없이 구현을 했다는 점에서 앞으로의 쓰임새가 기대되는 논문이다.
- Depth Search를 하는 방식으로 일종의 네트워크 경량화를 해낸다는 아이디어는 기존에도 많이 있었는데, 이를 Image Generation에 적용한 몇 안 되는 논문일 것이고 G-conditioned Dsicriminator를 통해 Discriminator를 상황에 맞게 학습시키는 방법은 앞으로도 많이 차용할 수 있다.

<!--truncate-->

## Main Method

<img className={styles.figCenter} src={figArchi} alt="architecture" />

**좌측: Generator의 Decoder, 우측: Discriminator**

### Sampling-based Multi-resolution Training

<img className={styles.figCenter} src={figTable} alt="table" />

MSG-GAN은 Generator를 학습하는 데 있어 다른 해상도를 지원하도록 학습하기 위해 모든 해상도에 대한 Discriminator를 각각 만들어서 이를 모두 사용했다. 하지만, 이러한 All-resolution training 방식은 FFHQ 처럼 큰 데이터셋에 대해 각각을 single-resolution으로 학습하는 것보다 좋지 않은 결과를 만들었다.

본 모델은 이를 Multi-resolution으로 학습할 수 있게 sampling 하는 방향으로 진행한다.

### Adaptive Channel Training

<img className={styles.figCenter} src={figAdaptiveCh} alt="adaptive_channel" />

바라는 것(전제): Important Channel들의 경우 sampling 하는 동안 보존될 것이다.

방식

- 이전 stage로부터 모델 Initialize를 진행한다.
- 이 때, Kernel Magnitude를 기준으로 High to Low로 sorting
- 0.25, 0.5, 0.75, 1 x의 비율 중 하나로 random하게 sampling 하도록 함.

이를 통해 모든 sub-network가 fewer channel만 가지고 있어도 실재적인 이미지를 생성하도록 했다. 다만, 이게 실제 full network로 생성한 이미지와는 다를 수 밖에 없었는데 이를 위해 consistent를 유지해주는 loss를 추가했다. (MSE (L2), LPIPS (Perceptual) Loss 기반)

### Generator-conditioned discriminator

가장 쉬운 방법은 Discriminator의 channel 수를 Generator에 맞춰 가며 줄이는 방식일 것이다. 다만, 이러한 방식은 Uniform한 channel ratio에만 적용되고, channel 수가 작아질 때에만 성능 향상에 도움이 되는 방법들이었다.

그래서 이를 대신해서 FC Layer를 추가하여 learnable하게 구조를 만들었다.

우선 Channel Configuration을 Encoding 하도록 한다. One-hot Encoding으로 위에 0.25, 0.5, 0.75, 1 중 각 resolution에 해당하는 layer가 무엇을 선택했는 지를 나타내는 방식이다. 여기서 이를 G Architecture Vector (g_arch)라고 부른다. 그리고 이를 FC에 실어 per-channel modulation을 할 수 있도록 Discrminator에 넘겨 준다. Real Image를 Discriminator에 넣을 때에는 g_arch를 random하게 부여한다.

Stablized Training 하기 위해 이를 전체 Discriminator에 적용하는 것은 아니고, Discriminator의 마지막 두 Block에만 적용하도록 했다.

## Result

<img className={styles.figCenter} src={figResultGraph} alt="fig5_result_graph" />
<img className={styles.figCenter} src={figChannelDiff} alt="fig6_channel_diff_result" />
<img className={styles.figCenter} src={figLsunResult} alt="fig7_LSUN_result" />
<img className={styles.figCenter} src={figMultiRes} alt="fig8_result_multiresolution" />
<img className={styles.figCenter} src={figLatentSpace} alt="fig9_latent_space_result" />