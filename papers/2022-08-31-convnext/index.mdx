---
slug: convnext
title: "A ConvNet for the 2020s (ConvNeXt)"
description: Convolutionì´ ë§í•©ë‹ˆë‹¤. í˜• ì•„ì§ ì£½ì§€ ì•Šì•˜ì–´ ì„ë§ˆ.
image: img/default.png
authors: [hkyu]
tags: [paper-review]
---

import clsx from 'clsx';
import styles from '../blog.module.css';

import figImagenetOneK from './image/figure1-imagenet1k.png';
import figBlock from './image/figure2-block.png';
import figBlockDesign from './image/figure3-block-design.png';
import figPretrain from './image/figure4-pretrain.png';
import figFinetune from './image/figure5-finetune.png';

[![arXiv](https://img.shields.io/badge/arXiv-2201.03545-brightgreen.svg?style=flat-square)](https://arxiv.org/abs/2201.03545)
[![githubio](https://img.shields.io/static/v1?message=Official%20Repo&logo=Github&labelColor=grey&color=blue&logoColor=white&label=%20&style=flat-square)](https://github.com/facebookresearch/ConvNeXt)

## Main Idea

Vision Taskì— Transformer ê¸°ë°˜ Architectureë¥¼ ì ‘ëª©í•˜ëŠ” ViTì˜ ë“±ì¥ ì´í›„, classification taskì— ëŒ€í•´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ViT ì´í›„ì— Swim Transformers ë“±ì˜ ë°©ë²•ë¡  ë“±ì€ segmentationì´ë‚˜ object detectionì—ë„ transformerë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ ë“±ì¥í•œ ë°©ë²•ë“¤ì´ì—ˆìŠµë‹ˆë‹¤. Swim Transformerì˜ ê²½ìš°, ì—¬ëŸ¬ ConvNetì„ priorë¡œ ì‚¼ëŠ” hybridí•œ ë°©ë²•ìœ¼ë¡œ ì´ë¥¼ í•´ê²°í•œ ê²ƒì´ íŠ¹ì§•ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ, hybridí•˜ë‹¤ê³  í•˜ê¸°ì—ëŠ” ê¸°ì¡´ Transformerì˜ í˜ì„ ë¹Œë¦° ê²ƒì¼ ë¿, ConvNet ìì²´ê°€ ê°€ì§€ê³  ìˆëŠ” inductive biasë¥¼ ìµœëŒ€í•œ ì‚¬ìš©í•œ ë°©ë²•ì€ ì•„ë‹™ë‹ˆë‹¤.

<!--truncate-->

ì €ìëŠ” ìˆœìˆ˜í•œ ConvNet(Transformer êµ¬ì¡°ë¥¼ ê³ë“¤ì´ì§€ ì•Šì€)ì˜ í˜ì„ í™•ì¸í•˜ê³ ì ê¸°ì¡´ì˜ standard ResNet(architecture + í•™ìŠµ ë°©ë²•ë¡ )ì—ì„œ vision Transformerì²˜ëŸ¼ í•™ìŠµí•  ìˆ˜ ìˆê²Œë” ì§€ê¸ˆê¹Œì§€ ë“±ì¥í•´ì˜¨ ì—¬ëŸ¬ Noveltyë“¤ì„ ì ‘ëª©í•´ë³´ê³ ì ì‹œë„í•©ë‹ˆë‹¤. íŠ¹íˆ, vision Transformer ëª¨ë¸ë“¤ì´ ë“±ì¥í•  ë•Œ í•­ìƒ ìƒˆë¡œìš´ í•™ìŠµ ë°©ë²•ë¡ ì„ í•¨ê»˜ ë“¤ê³  ë‚˜ì™€ì„œ ì„±ëŠ¥ í–¥ìƒì„ ì£¼ì¥í•˜ê³ ëŠ” í•˜ëŠ”ë°, ê·¸ í•™ìŠµ ë°©ë²•ë¡ ë“¤ì„ ê¸°ì¡´ ConvNetë“¤ì— ì ìš©í•´ë³¸ ì‚¬ë¡€ê°€ ë§ì´ ì—†ìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ì‹¤í—˜ì„ í†µí•´ ìµœê·¼ì— ë“±ì¥í•œ í•™ìŠµ ë°©ë²•ë¡ ì„ ì ìš©í•˜ê³  convolution block designì„ ìƒˆë¡­ê²Œ ë””ìì¸í•˜ë©´ ë” ì§ê´€ì ì¸ êµ¬ì¡°ë¡œ Transformerì— ê·¼ì ‘í•œ ì„±ëŠ¥ì„ ë³´ì¼ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

ê°€ë” ConvNeXt ë…¼ë¬¸ì„ ë“¤ì–´ë³´ê¸°ë§Œ í•˜ê³  ì°©ê°í•˜ëŠ” ê²ƒ ì¤‘ í•˜ë‚˜ê°€, ConvNeXtì˜ FLOPs ê°€ Transformerë³´ë‹¤ í˜„ì €íˆ ì‘ì€ ì±„ë¡œ ì„±ëŠ¥ì„ ë¹„ë“±í•˜ê²Œ ë‚¸ ê²ƒìœ¼ë¡œ ì•„ì‹œëŠ” ë¶„ë“¤ì´ ìˆìŠµë‹ˆë‹¤. ConvNeXtëŠ” architectureê°€ (inductive biasì—ì„œ ë“±ì¥í–ˆë˜) ConvNetì„ ìˆœìˆ˜í•˜ê²Œ ê¸°ë°˜ìœ¼ë¡œ í–ˆì„ ë¿, ê·¸ ëª¨ë¸ ì‚¬ì´ì¦ˆê°€ Transformers ë³´ë‹¤ ì ˆëŒ€ ì‘ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. ë‹¤ë§Œ, ìƒëŒ€ì ìœ¼ë¡œ Transformerë³´ë‹¤ëŠ” convolution layerì— ëŒ€í•œ compression ë°©ë²•ë¡ ë“¤ì´ ë” ë§ì´ ê³ ì•ˆëœë§Œí¼, ê·¸ ì§ê´€ì ì¸ êµ¬ì¡°ì— ì˜í•´ ë“±ì¥í–ˆë˜ compression ë°©ë²•ë¡ ë“¤ì„ ë‘ë£¨ ì ìš©í•˜ì—¬ ì•ìœ¼ë¡œ ê²½ëŸ‰í™”í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì´ ì¢€ ë” ìˆë‹¤ëŠ” ê²Œ ì œ ê°œì¸ì ì¸ ìƒê°ì…ë‹ˆë‹¤.

ì£¼ë¡œ ResNet 50 ì„ ê¸°ì¤€ìœ¼ë¡œ ì„±ëŠ¥ reportë¥¼ ì§„í–‰í•˜ê³ , ê° accuracyëŠ” random seedë¥¼ ë‹¤ë¥´ê²Œ í•˜ì—¬ 3ë²ˆì”© ì‹¤í—˜í•œ ê²°ê³¼ì…ë‹ˆë‹¤. ìš”ì¦˜ ë…¼ë¬¸ì¹˜ê³  ì² ì €í•˜ë‹¤ê³  ë³´ëŠ” ë¶„ë„ ê³„ì‹œê³ , í†µê³„ì ìœ¼ë¡œ ë¬´ìŠ¨ ì˜ë¯¸ê°€ ìˆëƒê³  í•˜ì‹œëŠ” ë¶„ë„ ìˆë”ë¼ê³ ìš” ã…ã… ë‹¤ë§Œ, publish ì´í›„ í•™ê³„ì—ì„œ ê²€ì¦í•˜ë©´ì„œ ConvNeXt ì‹¤í—˜ ê²°ê³¼ê°€ ì˜ëª»ëë‹¤ê³  í•˜ëŠ” ë…¼ë¬¸ì€ ë³¸ ì ì´ ì—†ìŠµë‹ˆë‹¤.

## Background Knowledge

### Examples of Representative ConvNet

VGGNet, Inceptions, ResNe(X)t, DenseNet, MobileNet, EfficientNet and RegNet

### ConvNet ì˜ ì£¼ìš” íŠ¹ì§•ë“¤

ì•„ë˜ëŠ” "sliding window"ë¥¼ ì‚¬ìš©í•˜ëŠ” convolutionì—ì„œ ê³ ì•ˆë˜ì—ˆê¸° ë•Œë¬¸ì— ìƒê²¨ë‚˜ëŠ” íŠ¹ì§•ë“¤ì…ë‹ˆë‹¤.

- Translation equivariant
  - Object detection ë“±ì˜ Taskì— ìˆì–´ì„œ íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤.
  - ê°€ë” equivariance, invariance í—·ê°ˆë ¤ í•˜ì‹œëŠ” ë¶„ë“¤ ê³„ì…”ì„œ ë§ì”€ë“œë¦¬ë©´, Patchë¥¼ ì´ë™í•˜ë“ , ê·¸ ê²°ê³¼ê°’ì„ ì´ë™í•œë‹¤ê³  feature vector ê°’ì´ ë°”ë€ŒëŠ” ê±´ ì•„ë‹ˆì—¬ì„œ invariant í•˜ë‹¤ê³ ë„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (g: Identity Mapping)
- Weight Sharing

## ë³€í™”1: Training Methodology

ì €ìëŠ” ResNet 50 ì— DeiT, Swim Transformerì™€ ìœ ì‚¬í•œ training recipeë¥¼ ì ìš©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒì´ ì–¼ë§ˆë‚˜ ì¼ì–´ë‚˜ëŠ” ì§€ë¥¼ ì‚´í´ë´…ë‹ˆë‹¤.

- Training epoch ì¦ê°€
  - 90 -> 300
- Optimizer ë³€ê²½
  - Adam -> AdamW
- Data augmentation
  - Mixup, Cutmix, RandAugment, Random Erasingì„ ì¶”ê°€
- Regularization scheme ì¶”ê°€
  - Stochastic depth
    - Depthë¥¼ ì´ë£¨ëŠ” ResBlocks ì¤‘ ì¼ë¶€ë¥¼ randomí•˜ê²Œ dropí•˜ë©´ì„œ í•™ìŠµí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ drop í•œë‹¤ëŠ” ì˜ë¯¸ëŠ” êµ¬í˜„ì—ì„œ ë´¤ì„ ë•ŒëŠ” ResBlockê³¼ identity mapping(skip connection) ì¤‘ ì„ íƒí•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.
      - "... Aims to shrink the depth of a network during training, while keeping it unchanged during testing. This is achieved by randomly dropping entireÂ ResBlocksÂ during training and bypassing their transformations through skip connections."
  - Label smoothing

ì´ ë°©ë²•ë¡  ë³€ê²½ì„ í†µí•´ ì•„ë˜ì™€ ê°™ì€ ì„±ëŠ¥ í–¥ìƒì´ ìˆì—ˆìŠµë‹ˆë‹¤.

- ResNet-50: 76.1% -> 78.8% (+2.7%)

ì–´ì©Œë©´ traditional ConvNetsì™€ vision Transformersì˜ ì°¨ì´ëŠ” í•™ìŠµ ë°©ë²•ì—ì„œ ì£¼ë¡œ ê¸°ì¸í•œ ê²Œ ì•„ë‹ê¹Œ ì‹¶ì„ ì •ë„ì˜ ì°¨ì´ì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.  
ì €ìëŠ” ì´ íŒŒíŠ¸ì—ì„œ ì°¾ì€ training recipeë¥¼ hyperparameterì™€ í•¨ê»˜ ìœ ì§€í•˜ë©´ì„œ ì•„ë˜ì˜ design ë³€ê²½ë“¤ì„ ì§„í–‰í•©ë‹ˆë‹¤.

## ë³€í™”2: í° í‹€ì—ì„œì˜ êµ¬ì¡° ë³€ê²½

### Stage Compute Ratioë¥¼ (3, 3, 9, 3)ìœ¼ë¡œ ë³€ê²½

ê¸°ì¡´ ResNetì˜ stageë³„ ë””ìì¸ì€ ë§¤ìš° ê²½í—˜ì ìœ¼ë¡œ ê²°ì •ë˜ì—ˆìŠµë‹ˆë‹¤.

<img className={styles.figCenter} src={figImagenetOneK} alt="imagenet1k" />

4ë²ˆì§¸ stageì— layerê°€ ë§ê¸° ë•Œë¬¸ì—(ResNet50 ê¸°ì¤€ 6), object detection ë“±ì˜ downstream taskì— ì ‘ëª©ë˜ê¸° ìœ„í•œ backboneìœ¼ë¡œ ë§ì´ ì“°ì¼ ìˆ˜ ìˆì—ˆê³ , íŠ¹íˆ ì´ ë•Œì˜ feature map ì‚¬ì´ì¦ˆê°€ 14 x 14 ì´ê¸°ì— detector headë¡œì„œì˜ ì—­í• ë„ ê²¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. Swim TransformerëŠ” ì´ì™€ëŠ” ë¹„ìŠ·í•˜ë‚˜ ì¡°ê¸ˆ ë‹¤ë¥¸ stage ratioë¥¼ ë³´ì—¬ì£¼ëŠ”ë°, ì‘ì€ ëª¨ë¸ì˜ ê²½ìš° (1, 1, 3, 1), í° ëª¨ë¸ì˜ ê²½ìš° (1, 1, 9, 1)ì˜ ë¹„ìœ¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

ì €ìëŠ” Swim-Tì™€ì˜ FLOPsë¥¼ ìœ ì‚¬í•œ ë¹„ìœ¨ë¡œ ê°€ì ¸ê°€ê¸° ìœ„í•´, ê¸°ì¡´ì˜ stage ratio (3, 4, 6, 3)ì„ (3, 3, 9, 3)ìœ¼ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.

ì´ ë°©ë²•ë¡  ë³€ê²½ì„ í†µí•´ ì•„ë˜ì™€ ê°™ì€ ì„±ëŠ¥ í–¥ìƒì´ ìˆì—ˆìŠµë‹ˆë‹¤.

- ResNet-50: 78.8% -> 79.4 (+0.6%, ëˆ„ì : +3.3%)

Network design spaceì— ê´€í•œ ì—°êµ¬ë“¤ì„ ì‚´í´ë³´ë©´, ì´ë³´ë‹¤ ì¶©ë¶„íˆ ë” ì¢‹ì€ stage compute ratioê°€ ìˆì„ ìˆ˜ë„ ìˆë‹¤ê³  ì €ìëŠ” ë§í•©ë‹ˆë‹¤.

### Patchë¥¼ ë§Œë“œëŠ” ì²« stem layerì„ Conv(ks=4, stride=4)ë¡œ ë³€ê²½ (non-overlapping conv.)

Stem cell designì€ ì•„í‚¤í…ì³ ê°€ì¥ ì²˜ìŒì— input imageë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í•´ì¤„ ì§€ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ResNetì—ì„œëŠ” kernel size 7x7, stride 2 ì˜ Conv layer(2x downsample)ê³¼ max-pooling(2x downsample)ì„ í†µí•´ 4x downsample ì‹œí‚¤ëŠ” stem cell designì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. vision Transformer ë“¤ì€ ì´ë³´ë‹¤ë„ ë” ê³¼ê°í•˜ê²Œ patchë¥¼ ë§Œë“œëŠ” ì „ëµì„ ì‚¬ìš©í•˜ëŠ” ë°, 14x14 ë˜ëŠ” 16x16ì˜ ì•„ì£¼ í° kernel sizeë¥¼ ê°€ì§„ Conv layerë¥¼ ê²¹ì¹˜ëŠ” ë¶€ë¶„ì´ ì—†ê²Œë”(kernel sizeì™€ strideê°€ ë™ì¼) ì„¤ì •í•©ë‹ˆë‹¤. Swim Transformerì˜ ê²½ìš°, ì´ designì— ì¶”ê°€ë¡œ multi-stage designì„ ìœ„í•´ 4x4 patch sizeì˜ layerë¥¼ ë³„ê°œë¡œ ë‘ì—ˆìŠµë‹ˆë‹¤.

ì €ìëŠ” ResNet-style stem cellë¡œì„œ kernel size 4x4, stride 4ë¡œ ì„¤ì •í•œ conv. layer(4x downsample)ë¥¼ stem cell designìœ¼ë¡œ ì„ ì •í–ˆìŠµë‹ˆë‹¤.

ì´ ë°©ë²•ë¡  ë³€ê²½ì„ í†µí•´ ì•„ë˜ì™€ ê°™ì€ ì„±ëŠ¥ í–¥ìƒì´ ìˆì—ˆìŠµë‹ˆë‹¤.

- ResNet-50: 79.4% -> 79.5% (+0.1%, ëˆ„ì : +3.4%)

ResNetì—ì„œ patchë¥¼ ë§Œë“œëŠ” ë°©ë²•ì— ìˆì–´ì„œëŠ” ì´ë ‡ê²Œ ViT ë“±ì—ì„œ ë³´ì—¬ì¤€ ë” ì‰¬ìš´ ë°©ë²•ë“¤ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒìœ¼ë¡œ êµì²´ ê°€ëŠ¥í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ë³€í™”3: ResNeXt ì•„ì´ë””ì–´ ì ìš©í•˜ê¸°

ResNeXt ì—ì„œëŠ” bottleneck blockì—ì„œ grouped convolutionì„ ì‚¬ìš©í•¨ìœ¼ë¡œì„œ, FLOPsë¥¼ ì¤„ì´ê³  network width(# channel in hidden layers) ë¥¼ ëŠ˜ë¦´ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

ì €ìëŠ” grouped convolutionì˜ ë§¥ë½ì—ì„œ depthwise convolutionì„ ì‚¬ìš©í•©ë‹ˆë‹¤. Depthwise convolutionì€ per-channelë¡œ self-attentionì˜ weighted sumê³¼ ë™ì¼í•œ ì—­í• ì„ í•˜ê²Œ ë˜ëŠ”ë°ìš”. ì¦‰, spatial dimensionìœ¼ë¡œë§Œ ì •ë³´ë¥¼ ì„ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

ì´ë¥¼ í†µí•´ FLOPsëŠ” íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì´ë©´ì„œë„ ì •í™•ë„ëŠ” ë”ìš± ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Widthë¥¼ í™•ì¥í•  ìˆ˜ ìˆê²Œ ëœ ë§Œí¼, widthë¥¼ Swim Transformerë¥¼ ë”°ë¼ 64ì—ì„œ 96ìœ¼ë¡œ ëŠ˜ë¦¬ê²Œ ë˜ì—ˆë‹¤. ê·¸ë¦¬ê³  ì´ë¥¼ í†µí•´ ì•„ë˜ì™€ ê°™ì€ ì„±ëŠ¥ í–¥ìƒì´ ìˆì—ˆìŠµë‹ˆë‹¤.

- ResNet-50: 79.5% -> 80.5% (+1.0%, ëˆ„ì : +4.4%)

<img className={clsx(styles.figCenter, styles.medium)} src={figBlock} alt="block" />

(a): ResNeXt block / (b): inverted bottleneck / (c): position switch of depthwise conv layer

## ë³€í™”4: Inverted Bottleneck ì ìš©í•˜ê¸°

Transformerì—ì„œì˜ inverted bottleneckì€ MLP block ì¤‘ hidden layerì˜ dimensionì´ input dimensionqhek 4ë°° í¬ê²Œ ë””ìì¸ ëœ ê²ƒì„ ë§í•©ë‹ˆë‹¤. ConvNetì—ì„œë„ inverted bottleneckì€ MobileNetV2ì—ì„œ ë“±ì¥í•œ ì´í›„ ë‘ë£¨ ì“°ì´ê³  ìˆëŠ”ë°, layerì˜ í˜•íƒœë§Œ ë‹¤ë¥¼ ë¿ Transformerì—ì„œ ì‚¬ìš©í•˜ëŠ” inverted blockê³¼ ìœ ì‚¬í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ë°˜ì˜í•˜ë©´, ìœ„ figure ë‚´ (a)ì—ì„œ (b)ë¡œì˜ ë³€í™”ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Depthwise convolution(ë³´ë¼ìƒ‰)ì˜ FLOPs ëŠ” ëŠ˜ì–´ë‚˜ì§€ë§Œ ì „ì²´ ë„¤íŠ¸ì›Œí¬ì˜ FLOPsëŠ” ì¤„ì–´ë“œëŠ”ë°, ì´ëŠ” downsamplingì„ ì§„í–‰í•˜ëŠ” residual block ë‚´ì˜ 1x1 conv layer (shortcut layer) ì˜ FLOPsê°€ ì¤„ì–´ë“¤ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤(layer ë³„: (384 -> 384) 1x1 conv -> (96 -> 96) 1x1 conv).

ì €ìëŠ” inverted bottleneck êµ¬ì¡°ë¥¼ ì ìš©í–ˆê³ , ì•„ë˜ì™€ ê°™ì€ ì„±ëŠ¥ í–¥ìƒì´ ìˆì—ˆìŠµë‹ˆë‹¤.

- ResNet-50: 80.5% -> 80.6% (+0.1%, ëˆ„ì : +4.5%)

## ë³€í™”5: í° ì‚¬ì´ì¦ˆì˜ Kernelì„ ì´ìš©í•˜ê¸°

Vision Transformerì—ì„œ ì‚¬ìš©í•˜ëŠ” self-attentionì€ non-localí•œ íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆì–´, ì‚¬ì‹¤ìƒ receptive fieldê°€ globalí•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ì™€ëŠ” ë°˜ëŒ€ë¡œ ConvNetì—ì„œëŠ” GPUì˜ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬ íš¨ìœ¨ì ì¸ ì—°ì‚°ì„ ìœ„í•´ VGG networkë¥¼ ì‹œì‘ìœ¼ë¡œ 3x3ì˜ ì‘ì€ ì‚¬ì´ì¦ˆì˜ kernel ì‚¬ì´ì¦ˆë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. Swim TransformerëŠ” self-attentionì„ ì‚¬ìš©í•˜ëŠ” ë°ì— ìˆì–´ local windowë¥¼ ì ìš©í•˜ëŠ”ë°, ì—¬ê¸°ì„œëŠ” kernel sizeë¥¼ ìµœì†Œ 7x7 ë¡œ ì¡ì•„ì„œ ì‚¬ìš©í–ˆì—ˆìŠµë‹ˆë‹¤. ì €ìëŠ” ConvNetì—ë„ large kernel sizeë¥¼ ì ìš©í•´ë³´ê³ ì í•©ë‹ˆë‹¤.

ìš°ì„  kernel sizeë¥¼ í‚¤ìš°ê¸° ìœ„í•´ì„œëŠ” depthwise conv. ì˜ ìœ„ì¹˜ë¥¼ 1x1 conv. ì•ìœ¼ë¡œ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” Transformerì—ì„œ MSA(Multi-head Self Attention)ê°€ MLP layer ì•ì— ìˆëŠ” êµ¬ì¡°ì™€ ìœ ì‚¬í•˜ê²Œ ê°€ì ¸ê°€ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.

ì´ ìƒíƒœì—ì„œ ì €ìëŠ” kernel sizeë¥¼ 3, 5, 7, 9, 11 ë“±ì˜ í¬ê¸°ë¡œ ë°”ê¿”ê°€ë©´ì„œ ì‹¤í—˜ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. Kernel sizeê°€ ë‹¬ë¼ì§„ë‹¤ê³  FLOPsì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ë¯¸ë¯¸í•©ë‹ˆë‹¤. ì €ìë“¤ì˜ ì‹¤í—˜ì„ í†µí•´ 7x7ë³´ë‹¤ í° kernelì—ì„œëŠ” ì„±ëŠ¥ì´ ë” ì¦ê°€í•˜ì§€ ì•Šê³  saturate ë˜ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

ì´ë¥¼ í†µí•´ inverted bottleneckê¹Œì§€ ì ìš©í–ˆì„ ë•Œì™€ ë™ì¼í•œ accuracyë¥¼ ë³´ì´ë©´ì„œë„ FLOPsëŠ” 4.6Gì—ì„œ 4.2Gë¡œ ë‚®ì¶œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

## ë³€í™”6: Activation, Normalization Layer ë³€ê²½í•˜ê¸°

<img className={clsx(styles.figCenter, styles.medium)} src={figBlockDesign} alt="block-design" />

ê°€ì¥ ìš°ì¸¡ ConvNeXt blockì´ ì €ìê°€ ìµœì¢…ì ìœ¼ë¡œ ë””ìì¸í•œ í˜•íƒœì…ë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ ëª¨ë‘ í™•ì¸í•˜ì‹œê³  ì € blockì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ë“¤ì´ ì˜ ë°˜ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”ğŸ˜Š.

### ReLUë¥¼ GELUë¡œ ë³€ê²½

ConvNetì—ì„œëŠ” ì•„ì§ë„ ReLUê°€ ë‘ë£¨ ì“°ì´ê³ , original Transformer ë…¼ë¬¸ì—ì„œë„ ReLUë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, ê·¸ ì´í›„ ë“±ì¥í•œ NLP Transformer(BERT, GPT-2)ì™€ ViTì—ì„œëŠ” GELU(Gaussian Error Linear Unit)ì„ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì´ë¥¼ ì ìš©í–ˆì„ ë•Œ, ë³„ë„ì˜ ì„±ëŠ¥ í–¥ìƒì€ ì—†ì—ˆì§€ë§Œ, GELUê°€ ConvNetì—ë„ ì ìš©ë  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ ë³€í™”ì ì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Activation Functionì„ ì ê²Œ ì“°ê¸°

Transformer blockì—ì„œë„ MLP block ë‚´ activation 1ë²ˆ ì“°ì´ëŠ” ê²ƒ ì™¸ë¡œëŠ” ì“°ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ëŠ” 1x1 conv. ë’¤ì—ê¹Œì§€ activationì„ ë¶™ì´ëŠ” ConvNetì—ì„œì˜ í–‰íƒœì™€ëŠ” ë§¤ìš° ë‹¤ë¦…ë‹ˆë‹¤. ì €ìëŠ” Transformer block designì„ ë”°ë¼, residual block ë‚´ì— ëª¨ë“  GELU activationì„ ì§€ìš°ê³ , 1x1 layer ì‚¬ì´ì— activation í•˜ë‚˜ë§Œ ë‚¨ê²¨ë‘ì—ˆìŠµë‹ˆë‹¤. ì´ì™€ ê°™ì€ ë³€í™”ë¥¼ í†µí•´ ì•„ë˜ì™€ ê°™ì€ ì„±ëŠ¥ í–¥ìƒì´ ìˆì—ˆìŠµë‹ˆë‹¤.

- ResNet-50: 80.6% -> 81.3% (+0.7%, ëˆ„ì : +5.2%)

ì´ ì„±ëŠ¥ì€ Swim-Tì™€ ë™ì¼í•œ ì„±ëŠ¥ì…ë‹ˆë‹¤.

### Normalizationë„ ì ê²Œ ì“°ê¸°

Transformerì—ì„œëŠ” normalization layerë„ ì ê²Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì €ìëŠ” ì´ë¥¼ ë”°ë¼ 1x1 conv ì•ì— í•˜ë‚˜ì˜ BN(Batch Normalization)ë§Œì„ ë†”ë‘ê³ , ë‚˜ë¨¸ì§€ normalization layerë¥¼ ì§€ì› ìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì•„ë˜ì™€ ê°™ì€ ì„±ëŠ¥ í–¥ìƒì´ ìˆì—ˆìŠµë‹ˆë‹¤.

- ResNet-50: 81.3% -> 81.4% (+0.1%, ëˆ„ì : +5.3%)

ì¬ë°ŒëŠ” ì ì€ ì´ëŸ¬í•œ ë³€í™”ë¥¼ í†µí•´ Transfomerë³´ë‹¤ë„ ì˜¤íˆë ¤ normalization layerê°€ ì ì–´ì¡ŒìŠµë‹ˆë‹¤. ì´ëŠ” Transformer layerëŠ” block ì´ˆì…ì— LN((Layer Normalization) ì„ ì·¨í•˜ëŠ”ë°, ì €ìëŠ” BNì„ ë¶™ì¸ë‹¤ê³  ì„±ëŠ¥ì´ ì¢‹ì•„ì§€ì§€ ì•Šì•„ì„œ ê·¸ëƒ¥ ì§€ì› ë‹¤ê³  í•©ë‹ˆë‹¤.

### Batch Normalization ëŒ€ì‹  Layer Normalization

ë§ì€ vision taskì—ì„œ BNì´ ì‚¬ë‘ë°›ê³  ìˆëŠ” ê²ƒì€ ì‚¬ì‹¤ì¸ë°ìš”. í•˜ì§€ë§Œ, Transformerì—ì„œëŠ” ì´ë¯¸ LNì„ ì“°ë©´ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ ê²½ìš°ê°€ ë§ì•˜ìŠµë‹ˆë‹¤. ì €ìëŠ” ì´ ìƒíƒœì—ì„œ LNì„ ì ìš©í•´ì„œë„ í•™ìŠµí•˜ëŠ” ë° ë¬´ë¦¬ê°€ ì—†ìŒì„ í™•ì¸í–ˆê³  ì˜¤íˆë ¤ ì•„ë˜ì™€ ê°™ì€ ì„±ëŠ¥ í–¥ìƒì´ ìˆì—ˆìŠµë‹ˆë‹¤.

- ResNet-50: 81.4% -> 81.5% (+0.1%, ëˆ„ì : +5.4%)

### Separate Downsampling Layer ì‚¬ìš©

ì´ ë‚´ìš©ì€ block ë‚´ë¶€ì— ë°˜ì˜ëœ ë‚´ìš©ì´ ì•„ë‹ˆë¼, stage ë„˜ì–´ê°€ë©´ì„œ downsampleì„ í•  ë•Œì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤. ìœ„ diagramì—ëŠ” ë“œëŸ¬ë‚˜ì§€ ì•ŠëŠ” ë¶€ë¶„ì´ë‹ˆ ì°¸ê³ í•´ì£¼ì„¸ìš”~    
Swim Transformerê°€ patch mergingì„ í•  ë•Œ 2x2 neighborhood patchë“¤ì˜ channelì„ concatí•˜ì—¬(4C) ì´ì— ëŒ€í•´ 2C ì˜ channel sizeê°€ ë˜ë„ë¡ ë‚´ë±‰ìŠµë‹ˆë‹¤. ì´ë¥¼ Conv. ë¡œ í‘œí˜„í•˜ë©´ channel sizeê°€ 2ë°°ê°€ ë˜ê³ , kernel sizeëŠ” 2x2, stride 2ì¸ ê²ƒì…ë‹ˆë‹¤. ì €ìëŠ” ResNetì—ì„œ kernel size 3x3, stride 2, padding 1 ë¡œ ë§ˆì¹˜ ê³µì‹ì²˜ëŸ¼ ì“°ì´ë˜ downsampleí•˜ëŠ” conv. layer ëŒ€ì‹ ì— Swim Transformerì—ì„œì˜ downsample ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê·¸ëƒ¥ ì´ë¥¼ ëŒ€ì¹˜ì‹œí‚¤ë©´ í•™ìŠµì´ diverge ë˜ëŠ”ë°, block-levelì—ì„œ spatial resolutionì´ ë³€ê²½ë˜ëŠ” ì§€ì ì— LNì„ ì ë‹¹íˆ ë„£ì–´ì£¼ë©´ ì´ì— ëŒ€í•´ í•™ìŠµì´ stabilize ë˜ëŠ” ê²ƒì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤. ì´ëŠ” Swim Transformerë„ ì ìš©ëœ ë°©ì‹ì…ë‹ˆë‹¤.

ê·¸ë¦¬ê³  ì´ë¥¼ í†µí•´ ìµœì¢…ì ìœ¼ë¡œ ConvNeXtëŠ” ì•„ë˜ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

- ResNet-50: 81.5% -> 82.0% (+0.5%, ëˆ„ì : +5.9%)

## Training Details

ì €ìëŠ” ë³¸ ëª¨ë¸ì„ ì–´ë–»ê²Œ í•™ìŠµí–ˆëŠ” ì§€ Hyperparameterì™€ í•™ìŠµ ì„¸íŒ…ë„ í•¨ê»˜ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.  
Augmentation, optimizer ë“± ì—¬ëŸ¬ ë¶€ë¶„ì—ì„œ ë“±ì¥í•œ ìµœì‹ ì˜ í•™ìŠµ ë°©ë²•ë¡ ë“¤ì„ í•œ ê³³ì— ëª¨ì•„ë‘” ëŠë‚Œì…ë‹ˆë‹¤.

### (Pre-)Training Settings

<img className={clsx(styles.figCenter, styles.small)} src={figPretrain} alt="pretrain" />

### Finetuning Settings

<img className={clsx(styles.figCenter, styles.small)} src={figFinetune} alt="finetune" />
