<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.17">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Hyoung-Kyu Song RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Hyoung-Kyu Song Atom Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-223362952-2","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
<link rel="alternate" type="application/rss+xml" href="/story/rss.xml" title="Hyoung-Kyu Song RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/story/atom.xml" title="Hyoung-Kyu Song Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/papers/rss.xml" title="Hyoung-Kyu Song RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/papers/atom.xml" title="Hyoung-Kyu Song Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><title data-rh="true">2 posts tagged with &quot;gan&quot; | Hyoung-Kyu Song</title><meta data-rh="true" property="og:title" content="2 posts tagged with &quot;gan&quot; | Hyoung-Kyu Song"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://deepkyu.github.io//papers/tags/gan"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://deepkyu.github.io//papers/tags/gan"><link data-rh="true" rel="alternate" href="https://deepkyu.github.io//papers/tags/gan" hreflang="en"><link data-rh="true" rel="alternate" href="https://deepkyu.github.io//papers/tags/gan" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.7928c2ca.css">
<link rel="preload" href="/assets/js/runtime~main.0e5c39a1.js" as="script">
<link rel="preload" href="/assets/js/main.cb9fb5e7.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Deepkyu" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/logo.svg" alt="Deepkyu" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title"></b></a><a class="navbar__item navbar__link" href="/blog">Blog</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/papers">Reviews</a><a class="navbar__item navbar__link" href="/story">Story</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/cv">CV</a><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://www.linkedin.com/in/deepkyu" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_S7eR toggle_TdHA toggleDisabled_f9M3"><div class="toggleButton_rCf9" role="button" tabindex="-1"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_v35p"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_nQuB"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></div><input type="checkbox" class="toggleScreenReader_g2nN" aria-label="Switch between dark and light mode (currently light mode)"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-tags-post-list-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_a9qW thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_uKok margin-bottom--md">All Posts</div><ul class="sidebarItemList_Kvuv"><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/papers/acon">Activate or Not: Learning Customized Activation</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/papers/diffaugment">Differentiable Augmentation for Data-Efficient GAN Training</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/papers/freezed">FreezeD: a Simple Baseline for Fine-tuning GANs</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>2 posts tagged with &quot;gan&quot;</h1><a href="/papers/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_rzP5" itemprop="headline"><a itemprop="url" href="/papers/diffaugment">Differentiable Augmentation for Data-Efficient GAN Training</a></h2><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2021-05-03T00:00:00.000Z" itemprop="datePublished">May 3, 2021</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/deepkyu.png" alt="Hyoung-Kyu Song"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Hyoung-Kyu Song</span></a></div><small class="avatar__subtitle" itemprop="description">AI Researcher (Vision)</small></div></div></div></div></header><meta itemprop="image" content="https://deepkyu.github.io//img/default.png"><div class="markdown" itemprop="articleBody"><p><a href="https://arxiv.org/abs/2006.10738" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-2006.10738-brightgreen.svg?style=flat-square" alt="arXiv"></a>
<a href="https://github.com/mit-han-lab/data-efficient-gans" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?message=Official%20Repo&amp;logo=Github&amp;labelColor=grey&amp;color=blue&amp;logoColor=white&amp;label=%20&amp;style=flat-square" alt="githubio"></a></p><blockquote><p>Zhao, Shengyu, et al. &quot;Differentiable augmentation for data-efficient gan training.&quot;<br>
<!-- -->Advances in Neural Information Processing Systems 33 (2020): 7559-7570.</p></blockquote><p>참고로 Song Han 연구실은 Neural Network Compression 분야에 있어 Top을 달리고 있는 연구실이다. 후에 소개할 AnycostGAN에서도 DiffAugment가 언급이 된다.</p><p>Han Lab은 기존에는 방법론에 있어 Network Pruning, KD(Knowledge Distillation) 등에 집중을 했고, TinyTL 등 Activation에 대한 경량화도 연구를 진행했다. 다만, 대부분 Task가 Image Recognition에 국한되어 있었다. Song Han은 CVPR2020에서 GAN Compression이라는 논문을 통해 Image Generation에 대한 Compression 논문을 시작으로, GAN 관련 연구를 지속해서 이어오고 있다. </p><h2 class="anchor anchorWithStickyNavbar_mojV" id="배경-지식">배경 지식<a class="hash-link" href="#배경-지식" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_mojV" id="기존의-regularization">기존의 Regularization<a class="hash-link" href="#기존의-regularization" title="Direct link to heading">​</a></h3><p>GAN Training 자체가 굉장히 Unstable한 Process이기 때문에, 추가적인 Regularization이 많이 필요하다. 지금까지 여러가지 Regularization 방식들이 등장했다.</p><ul><li>Instance Noise</li><li>Jensen-Shannon Regularization</li><li>Gradient Penalty</li><li>Spectral Normalization</li><li>Adversarial Defense Regularization</li><li>Consistency Regularization</li></ul><p>이러한 Regularization Method들은 Input 이미지에 대해 대응하는 것이지, augmentation에 대해 소화할 수 있는 방법들이 아니다.</p><p>저자는 여러 가지 Augmentation에 대해서도 잘 working 하는 Discriminator를 구축하고자 했다.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="d는-지금까지-overfitting-해왔다">D는 지금까지 Overfitting 해왔다<a class="hash-link" href="#d는-지금까지-overfitting-해왔다" title="Direct link to heading">​</a></h3><img class="figCenter__7gH" src="/assets/images/d_overfitting-0fde96f1fa39bd9365ce7230b620fffb.png" alt="d_overfitting"><p>BigGAN을 적은 데이터에 대해 학습했을 때, 학습을 하다가 collapse하는 걸 보여주는 Figure다. 왼쪽에서 보면 빨간색(CIFAR-10 10%만 가지고 학습) 그래프가 튀어버리는 걸 볼 수 있다. 이게 왜 그럴까 하고 Discriminator를 보면, 아니나 다를까 Training Accuracy가 빠르게 학습이 돼서 그렇다.</p><p>그런데 D에 대해 각 Iteration에 대한 Validation Acc.를 측정해보면, mode collapse가 되었다는 걸 볼 수 있다. 즉, D가 training set 을 memorize 해왔고, 이로 인해 generalize가 안됐다는 걸 보여준다.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="training-method">Training Method<a class="hash-link" href="#training-method" title="Direct link to heading">​</a></h2><img class="figCenter__7gH medium_sJ4m" src="/assets/images/training_method-182e7e89d5035fa3118b77161271b12b.png" alt="training_method"><p>DiffAugment의 학습 방법을 보여주는 그림.</p><p>원본 이미지(x), 생성한 이미지(G(z)) 모두에 augmentation(T)을 적용한다.</p><p>Augmentation Senario에 따라서 여러 가지 Case로 나눌 수 있다.</p><p>Augment Reals Only: Real 이미지에 대해만 Augmentation을 진행함 (i만 진행.)
→ Augmentation 한 걸 그대로 모방하여 생성한다.</p><p>Augment D Only: Discriminator에 넣는 Input들에 대해 진행함 (i, ii 만 진행. iii는 그대로)
→ Unbalanced Optimization 에 의해 Diverge 해버린다.</p><p>D perfectly classifies the augmented images (both T(x) and T(G(z)) but barely
recognizes G(z) (i.e., fake images without augmentation)
이 때문에 G의 gradient update를 할 때, Discriminator가 잘 working 하지 못하면서, G에 대한 학습에 방해가 됨.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="result">Result<a class="hash-link" href="#result" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_mojV" id="stylegan2와-비교">StyleGAN2와 비교<a class="hash-link" href="#stylegan2와-비교" title="Direct link to heading">​</a></h3><img class="figCenter__7gH" src="/assets/images/vs_stylegan2-f1b3f845a404ca098b35e023e87f8a99.png" alt="vs_stylegan2"><p>기존 StyleGAN2과 본 논문에서 제시하는 DiffAugment를 적용했을 때를 비교하는 Figure.<br>
<!-- -->StyleGAN2는 데이터가 작아질수록, FID, IS 값의 변화가 dramatic한데, DiffAugment는 상대적으로 적은 데이터에 대해서도 generalize되어 있다는 걸 볼 수 있다. StyleGAN2가 작은 데이터에 generalize가 안된다는 건 좀 알려진 사실이었으니, Discriminator Training Method에 집중한 ADA나 Freeze D와 비교하는 Figure를 자연스럽게 기대하게 된다.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="low-shot-generation">Low-Shot Generation<a class="hash-link" href="#low-shot-generation" title="Direct link to heading">​</a></h3><img class="figCenter__7gH" src="/assets/images/result_compare-acc36d84cc9ea455714866e23cef7a61.png" alt="result_compare"><p>Low-shot generation without pre-training.</p><p>각각 오바마 100장, 고양이 160장, 강아지 389장만을 가지고 학습을 하여 생성해낸 이미지들이다. (w/o pre-training)</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="result-1">Result<a class="hash-link" href="#result-1" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_mojV" id="training-performance">Training Performance<a class="hash-link" href="#training-performance" title="Direct link to heading">​</a></h3><img class="figCenter__7gH" src="/assets/images/augmentation_type_result-e03bdd14ef6248c21157d69ba3f953af.png" alt="augmentation_type_result"><p>Augmentation 조합에 따라 달라지는 DiffAugment Training Performance (CIFAR-10 Data 100% 사용)</p><p>BigGAN 대비 Discriminator가 Validation에 있어서도 generalize 하여 학습되었다고 볼 수 있다. DiffAugment 자체는 Low Dataset에 대해서도 Generation을 안정적으로 할 수 있다는 Novelty를 가지고 있지만, 본 Figure는 BigGAN도 학습했다고 하는 데이터가 CIFAR-10 전체를 사용한 것이었으니, 해당 조건으로 Comparison을 한 것으로 해석할 수 있다.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="interpolation도-가능하다">Interpolation도 가능하다<a class="hash-link" href="#interpolation도-가능하다" title="Direct link to heading">​</a></h3><img class="figCenter__7gH" src="/assets/images/interpolation-a37d53f43c37be1bde34d1839ecf1837.png" alt="interpolation"><p>Style Space에서 Interpolation이 가능함을 보여주는 Figure.</p><p>적은 데이터였지만 (오바마, 고양이, 강아지 참조), Interpolation이 가능할 정도로 generalize하게 학습이 되었다.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="model-size에-대한-분석">Model Size에 대한 분석<a class="hash-link" href="#model-size에-대한-분석" title="Direct link to heading">​</a></h3><img class="figCenter__7gH" src="/assets/images/model_size_fid-b395637cdd2677201a79958933acd29f.png" alt="model_size_fid"><p>Model size가 FID에 얼마나 영향을 주는가에 대한 Figure</p><p>CIFAR-10 데이터 10%에 대해서만 학습을 했을 때, generalize가 될 수 있는 가를 다룬 부분이다. BigGAN 대비 channel size를 줄여가며 비교를 해봐도, 어떤 capacity든 상관없이 더 좋은 성능을 보여준다. StyleGAN2에서 사용하는 R1 Regularization 관련해서도, hyperparameter가 동일한 세팅일 때 더 나은 FID를 보여줬다.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="regularization">Regularization<a class="hash-link" href="#regularization" title="Direct link to heading">​</a></h3><div class="admonition admonition-tip alert alert--success"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="16" viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</h5></div><div class="admonition-content"><p><strong>R1 Regularization</strong><br>
<!-- -->Gradient Penalty로 regularize 하는 방식으로, Discriminator의 Real Data에 대해 Penalize를 준다.</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>R</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mi>ψ</mi><mo stretchy="false">)</mo><mo>:</mo><mo>=</mo><mfrac><mi>γ</mi><mn>2</mn></mfrac><msub><mi mathvariant="normal">E</mi><mrow><msub><mi>p</mi><mi mathvariant="script">D</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mo fence="true">[</mo><msup><mrow><mo fence="true">∥</mo><mi mathvariant="normal">∇</mi><msub><mi>D</mi><mi>ψ</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo fence="true">∥</mo></mrow><mn>2</mn></msup><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">R_{1}(\psi):=\frac{\gamma}{2} \mathrm{E}_{p_{\mathcal{D}}(x)}\left[\left\|\nabla D_{\psi}(x)\right\|^{2}\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">ψ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">:=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.836em;vertical-align:-0.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1076em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathrm">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3567em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.02778em">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1433em"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size2">[</span></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em">∥</span><span class="mord">∇</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">ψ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em">∥</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.954em"><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size2">]</span></span></span></span></span></span></span></div><blockquote><p>when the generator distribution produces the true data distribution and the discriminator is equal to 0 on the data manifold, the gradient penalty ensures that the discriminator cannot create a non-zero gradient orthogonal to the data manifold without suffering a loss in the GAN game.</p></blockquote></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="ablation-for-augmentation">Ablation for Augmentation<a class="hash-link" href="#ablation-for-augmentation" title="Direct link to heading">​</a></h3><img class="figCenter__7gH" src="/assets/images/ablation_augmentation-6fad8d2422af1ae0b528dfa994cf5049.png" alt="ablation_augmentation"><p>여러 가지 Augmentation에 대해 FID를 확인해본 결과다.
Ablation을 진행한 끝에, color distortion, translation, cutout만 준 것으로 확인했다. (먼저 생각하고 준 건 아닌 것으로 확인했다.)
StyleGAN2의 FID이고, CIFAR-10 10% 데이터만을 가지고 Training 했을 때의 결과다.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/papers/tags/paper-review">paper-review</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/papers/tags/gan">gan</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Differentiable Augmentation for Data-Efficient GAN Training" href="/papers/diffaugment"><b>Read More</b></a></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/papers/tags/gan/page/2"><div class="pagination-nav__label">Older Entries</div></a></div></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Contents</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a class="footer__link-item" href="/papers">Reviews</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/story">Story</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/deepkyu" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://www.linkedin.com/in/deepkyu" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2022 Deepkyu. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.0e5c39a1.js"></script>
<script src="/assets/js/main.cb9fb5e7.js"></script>
</body>
</html>